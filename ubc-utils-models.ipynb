{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c5b9c4d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-12T15:57:00.160465Z",
     "iopub.status.busy": "2023-12-12T15:57:00.160068Z",
     "iopub.status.idle": "2023-12-12T15:57:11.294587Z",
     "shell.execute_reply": "2023-12-12T15:57:11.293157Z"
    },
    "papermill": {
     "duration": 11.144704,
     "end_time": "2023-12-12T15:57:11.297807",
     "exception": false,
     "start_time": "2023-12-12T15:57:00.153103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import copy\n",
    "import datetime\n",
    "import gc\n",
    "import glob\n",
    "import heapq\n",
    "import joblib\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "# Related third-party imports\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from colorama import Fore, Back, Style\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.cuda import amp\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "# Local application/library specific imports\n",
    "# (Your local imports here, if any)\n",
    "\n",
    "# Set up for colored terminal text\n",
    "b_ = Fore.BLUE\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Additional note: The following import seems to be from a very specific context or not typically used.\n",
    "# You might want to review if it's necessary or correct:\n",
    "# from joblib.externals.loky.backend.context import get_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1381d2",
   "metadata": {
    "papermill": {
     "duration": 0.003914,
     "end_time": "2023-12-12T15:57:11.308263",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.304349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9249d261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:57:11.318462Z",
     "iopub.status.busy": "2023-12-12T15:57:11.318057Z",
     "iopub.status.idle": "2023-12-12T15:57:11.328772Z",
     "shell.execute_reply": "2023-12-12T15:57:11.327167Z"
    },
    "papermill": {
     "duration": 0.018876,
     "end_time": "2023-12-12T15:57:11.331277",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.312401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e94e5c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:57:11.342347Z",
     "iopub.status.busy": "2023-12-12T15:57:11.341961Z",
     "iopub.status.idle": "2023-12-12T15:57:11.352522Z",
     "shell.execute_reply": "2023-12-12T15:57:11.351555Z"
    },
    "papermill": {
     "duration": 0.019486,
     "end_time": "2023-12-12T15:57:11.355090",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.335604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UBCModel(nn.Module):\n",
    "    '''\n",
    "    EfficientNet B0 fine-tune.\n",
    "    '''\n",
    "    def __init__(self, model_name, num_classes, pretrained=False, checkpoint_path=None):\n",
    "        '''\n",
    "        Fine tune for EfficientNetB0\n",
    "        Args\n",
    "            n_classes : int - Number of classification categories.\n",
    "            learnable_modules : tuple - Names of the modules to fine-tune.\n",
    "        Return\n",
    "            \n",
    "        '''\n",
    "        super(UBCModel, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward function for the fine-tuned model\n",
    "        Args\n",
    "            x: \n",
    "        Return\n",
    "            result\n",
    "        \"\"\"\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        output = self.linear(pooled_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64d1c12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:57:11.366039Z",
     "iopub.status.busy": "2023-12-12T15:57:11.365539Z",
     "iopub.status.idle": "2023-12-12T15:57:11.376667Z",
     "shell.execute_reply": "2023-12-12T15:57:11.374997Z"
    },
    "papermill": {
     "duration": 0.019666,
     "end_time": "2023-12-12T15:57:11.379365",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.359699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This model is used for binary classification on cancerous vs non-cancerous tiles \n",
    "class UBCBinaryModel(nn.Module):\n",
    "    '''\n",
    "    EfficientNet B0 fine-tune.\n",
    "    '''\n",
    "    def __init__(self, model_name, pretrained=False, checkpoint_path=None):\n",
    "        '''\n",
    "        Fine tune for EfficientNetB0\n",
    "        Args\n",
    "            learnable_modules : tuple - Names of the modules to fine-tune.\n",
    "        Return\n",
    "            \n",
    "        '''\n",
    "        super(UBCBinaryModel, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.linear = nn.Linear(in_features, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        logits = self.linear(pooled_features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c23699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:57:11.390013Z",
     "iopub.status.busy": "2023-12-12T15:57:11.389503Z",
     "iopub.status.idle": "2023-12-12T15:57:11.401498Z",
     "shell.execute_reply": "2023-12-12T15:57:11.400323Z"
    },
    "papermill": {
     "duration": 0.021268,
     "end_time": "2023-12-12T15:57:11.404908",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.383640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c8b3b",
   "metadata": {
    "papermill": {
     "duration": 0.00399,
     "end_time": "2023-12-12T15:57:11.413537",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.409547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "170e0764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T15:57:11.424263Z",
     "iopub.status.busy": "2023-12-12T15:57:11.423778Z",
     "iopub.status.idle": "2023-12-12T15:57:11.442079Z",
     "shell.execute_reply": "2023-12-12T15:57:11.440781Z"
    },
    "papermill": {
     "duration": 0.027386,
     "end_time": "2023-12-12T15:57:11.445142",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.417756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer, CONFIG):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'], verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        CONFIG['T_0'] = 10\n",
    "        CONFIG['T_mult'] = 2\n",
    "        CONFIG['min_lr'] = 1e-6\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG['T_0'], T_mult=CONFIG['T_mult'],\n",
    "                                                             eta_min=CONFIG['min_lr'], verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'ReduceLROnPlateau':\n",
    "        scheduler =  ReduceLROnPlateau(optimizer, mode='min', factor=kwargs.get('factor', 0.1), patience=kwargs.get('patience', 5), verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'LambdaLR':\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "    return scheduler\n",
    "\n",
    "def get_optimizer(optimizer_name, model):\n",
    "    if optimizer_name.lower() == \"adam\":\n",
    "        CONFIG['learning_rate'] = 1e-4\n",
    "        CONFIG['weight_decay'] = 1e-5\n",
    "        CONFIG['betas'] = (0.9, 0.999)\n",
    "        CONFIG['eps'] = 1e-8\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], betas=CONFIG['betas'], eps=CONFIG['eps'],  weight_decay=CONFIG['weight_decay'])\n",
    "    elif optimizer_name.lower() == \"sgd\":\n",
    "        CONFIG['learning_rate'] = 1e-3\n",
    "        CONFIG['weight_decay'] = 1e-3\n",
    "        CONFIG['momentum'] = 1e-3\n",
    "        optimizer = optim.SGD(model.parameters(), lr=CONFIG['learning_rate'], momentum=CONFIG['momentum'], weight_decay=CONFIG['weight_decay'])\n",
    "    elif optimizer_name.lower() == \"radam\":\n",
    "        CONFIG['learning_rate'] = 1e-4\n",
    "        CONFIG['weight_decay'] = 0\n",
    "        CONFIG['betas'] = (0.9, 0.999)\n",
    "        CONFIG['eps'] = 1e-8\n",
    "        optimizer = torch_optimizer.RAdam(\n",
    "            model.parameters(),\n",
    "            lr= CONFIG['learning_rate'],\n",
    "            betas=CONFIG['betas'],\n",
    "            eps=CONFIG['eps'],\n",
    "            weight_decay=CONFIG['weight_decay'],\n",
    "        )\n",
    "    elif optimizer_name.lower() == \"rmsprop\":\n",
    "        CONFIG['learning_rate'] = 0.256\n",
    "        CONFIG['alpha'] = 0.9\n",
    "        CONFIG['momentum'] = 0.9\n",
    "        CONFIG['weight_decay'] = 1e-5\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=CONFIG['learning_rate'], alpha=CONFIG['learning_rate'], \n",
    "                                  momentum=CONFIG['learning_rate'], weight_decay=CONFIG['learning_rate'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Optimizer given!\")\n",
    "    return optimizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d2341",
   "metadata": {
    "papermill": {
     "duration": 0.004128,
     "end_time": "2023-12-12T15:57:11.453993",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.449865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa042e1",
   "metadata": {
    "papermill": {
     "duration": 0.004093,
     "end_time": "2023-12-12T15:57:11.462547",
     "exception": false,
     "start_time": "2023-12-12T15:57:11.458454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6924515,
     "sourceId": 45867,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.787999,
   "end_time": "2023-12-12T15:57:13.723850",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-12T15:56:55.935851",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
