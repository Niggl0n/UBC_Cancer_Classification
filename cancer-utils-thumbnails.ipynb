{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28449f8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-13T13:52:51.131317Z",
     "iopub.status.busy": "2023-11-13T13:52:51.130768Z",
     "iopub.status.idle": "2023-11-13T13:53:02.110775Z",
     "shell.execute_reply": "2023-11-13T13:53:02.109519Z"
    },
    "papermill": {
     "duration": 10.990895,
     "end_time": "2023-11-13T13:53:02.113856",
     "exception": false,
     "start_time": "2023-11-13T13:52:51.122961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torchvision\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f5e947",
   "metadata": {
    "papermill": {
     "duration": 0.005338,
     "end_time": "2023-11-13T13:53:02.127435",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.122097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d077d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:53:02.142002Z",
     "iopub.status.busy": "2023-11-13T13:53:02.140744Z",
     "iopub.status.idle": "2023-11-13T13:53:02.162251Z",
     "shell.execute_reply": "2023-11-13T13:53:02.161059Z"
    },
    "papermill": {
     "duration": 0.03229,
     "end_time": "2023-11-13T13:53:02.165214",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.132924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UBCDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, apply_vertical_crop=True):\n",
    "        self.df = df\n",
    "        self.filenames = df.file_path.values\n",
    "        self.labels =  df.target_label.values\n",
    "        self.transforms = transforms\n",
    "        self.apply_vertical_crop = apply_vertical_crop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.filenames[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.apply_vertical_crop:\n",
    "            img = crop_vertical(img)\n",
    "                \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "               }\n",
    "\n",
    "def crop_vertical(image):\n",
    "    \"\"\"\n",
    "    Function crops images if multiple slices contained and separated by black vertical background.\n",
    "    \"\"\"\n",
    "    vertical_sum = np.sum(image, axis=(0, 2))\n",
    "\n",
    "    # Identify the positions where the sum is zero\n",
    "    zero_positions = np.where(vertical_sum == 0)[0]\n",
    "\n",
    "    if len(zero_positions)==0:\n",
    "        cropped_images = [image]\n",
    "    else:\n",
    "        # If the image does not start with a black area, add index 0\n",
    "        if zero_positions[0] != 0:\n",
    "            zero_positions = np.insert(zero_positions, 0, 0)\n",
    "\n",
    "        # If the image does not end with a black area, add the image width\n",
    "        if zero_positions[-1] != image.shape[1] - 1:\n",
    "            zero_positions = np.append(zero_positions, image.shape[1] - 1)\n",
    "\n",
    "        start_idx = zero_positions[0]\n",
    "        cropped_images = []\n",
    "\n",
    "        for idx in range(1, len(zero_positions)):\n",
    "            end_idx = zero_positions[idx]\n",
    "            if end_idx - start_idx > 1:  # If the width of the cropped section is greater than 1\n",
    "                cropped = image[:, start_idx:end_idx]\n",
    "                # only include samples which are of min size\n",
    "                if cropped.shape[1]>200:  \n",
    "                    cropped_images.append(cropped)\n",
    "                    # cv2.imwrite(f\"{save_prefix}_{idx}.jpg\", cropped)\n",
    "            start_idx = end_idx\n",
    "\n",
    "    final_crops = []\n",
    "    # remove black bars above/below the crops \n",
    "    for cropped in cropped_images:\n",
    "        horizontal_sum = np.sum(cropped, axis=(1, 2))\n",
    "        zero_positions = np.where(horizontal_sum == 0)[0]\n",
    "        img_ = np.delete(cropped, zero_positions, axis=0)\n",
    "        final_crops.append(img_)\n",
    "    if len(final_crops)==0:\n",
    "        return image\n",
    "    return final_crops[0]\n",
    "\n",
    "\n",
    "def custom_center_crop_or_resize(image, crop_size):\n",
    "    # If both dimensions of the image are greater than or equal to the desired size, apply CenterCrop\n",
    "    if image.shape[0] >= crop_size[0] and image.shape[1] >= crop_size[1]:\n",
    "        return A.CenterCrop(crop_size[0], crop_size[1])(image=image)[\"image\"]\n",
    "    # Else, just resize the image to the desired size\n",
    "    else:\n",
    "        return A.Resize(crop_size[0], crop_size[1])(image=image)[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e79736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:53:02.178183Z",
     "iopub.status.busy": "2023-11-13T13:53:02.177799Z",
     "iopub.status.idle": "2023-11-13T13:53:02.191508Z",
     "shell.execute_reply": "2023-11-13T13:53:02.190144Z"
    },
    "papermill": {
     "duration": 0.023859,
     "end_time": "2023-11-13T13:53:02.194695",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.170836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.RandomResizedCrop(512, 512, scale=(0.8, 1.0)),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.2),\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "        A.CoarseDropout(p=0.2),\n",
    "        A.Cutout(p=0.2),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225], \n",
    "            max_pixel_value=255.0, \n",
    "            p=1.0\n",
    "        ),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225], \n",
    "            max_pixel_value=255.0, \n",
    "            p=1.0\n",
    "        ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3a359e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:53:02.207798Z",
     "iopub.status.busy": "2023-11-13T13:53:02.207370Z",
     "iopub.status.idle": "2023-11-13T13:53:02.216748Z",
     "shell.execute_reply": "2023-11-13T13:53:02.215668Z"
    },
    "papermill": {
     "duration": 0.018949,
     "end_time": "2023-11-13T13:53:02.219379",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.200430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(df, fold, CONFIG):\n",
    "    df_train = df[df[\"kfold\"]!=fold].reset_index(drop=True)\n",
    "    df_valid = df[df[\"kfold\"]==fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = UBCDataset(df_train, transforms=data_transforms[\"train\"])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    valid_dataset = UBCDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    return train_loader, valid_loader, df_train, df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db282aa",
   "metadata": {
    "papermill": {
     "duration": 0.005307,
     "end_time": "2023-11-13T13:53:02.230385",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.225078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9732b279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:53:02.244080Z",
     "iopub.status.busy": "2023-11-13T13:53:02.243675Z",
     "iopub.status.idle": "2023-11-13T13:53:02.259272Z",
     "shell.execute_reply": "2023-11-13T13:53:02.258116Z"
    },
    "papermill": {
     "duration": 0.025506,
     "end_time": "2023-11-13T13:53:02.261969",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.236463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class EfficientNetB0(nn.Module):\n",
    "    '''\n",
    "    EfficientNet B0 fine-tune.\n",
    "    '''\n",
    "    def __init__(self, model_name, num_classes, pretrained=False, checkpoint_path=None):\n",
    "        '''\n",
    "        Fine tune for EfficientNetB0\n",
    "        Args\n",
    "            n_classes : int - Number of classification categories.\n",
    "            learnable_modules : tuple - Names of the modules to fine-tune.\n",
    "        Return\n",
    "            \n",
    "        '''\n",
    "        super(EfficientNetB0, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward function for the fine-tuned model\n",
    "        Args\n",
    "            x: \n",
    "        Return\n",
    "            result\n",
    "        \"\"\"\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        output = self.linear(pooled_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5be44f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:53:02.275221Z",
     "iopub.status.busy": "2023-11-13T13:53:02.274851Z",
     "iopub.status.idle": "2023-11-13T13:53:02.287711Z",
     "shell.execute_reply": "2023-11-13T13:53:02.285864Z"
    },
    "papermill": {
     "duration": 0.022693,
     "end_time": "2023-11-13T13:53:02.290410",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.267717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766b708b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:53:02.304509Z",
     "iopub.status.busy": "2023-11-13T13:53:02.304074Z",
     "iopub.status.idle": "2023-11-13T13:53:02.319131Z",
     "shell.execute_reply": "2023-11-13T13:53:02.317902Z"
    },
    "papermill": {
     "duration": 0.025538,
     "end_time": "2023-11-13T13:53:02.321653",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.296115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, OneCycleLR\n",
    "\n",
    "def get_lr_scheduler(optimizer, scheduler_type, **kwargs):\n",
    "    if scheduler_type == 'steplr':\n",
    "        return StepLR(optimizer, step_size=kwargs.get('step_size', 10), gamma=kwargs.get('gamma', 0.1))\n",
    "    \n",
    "    elif scheduler_type == 'plateau':\n",
    "        return ReduceLROnPlateau(optimizer, mode='min', factor=kwargs.get('factor', 0.1), patience=kwargs.get('patience', 5), verbose=True)\n",
    "    \n",
    "    elif scheduler_type == 'onecycle':\n",
    "        return OneCycleLR(optimizer, max_lr=kwargs.get('max_lr', 0.01), steps_per_epoch=len(train_loader), epochs=kwargs.get('num_epochs', 10))\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scheduler type: {scheduler_type}\")\n",
    "        \n",
    "def fetch_scheduler(optimizer, CONFIG):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'], verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'], verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'ReduceLROnPlateau':\n",
    "        scheduler =  ReduceLROnPlateau(optimizer, mode='min', factor=kwargs.get('factor', 0.1), patience=kwargs.get('patience', 5), verbose=False)\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "def get_optimizer(optimizer_name, model, CONFIG):\n",
    "    if optimizer_name.lower() == \"adam\":\n",
    "            optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'],  weight_decay=CONFIG['weight_decay'])\n",
    "    elif optimizer_name.lower() == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=CONFIG['learning_rate'], momentum=CONFIG['momentum'], weight_decay=CONFIG['weight_decay'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Optimizer given!\")\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f8e464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:53:02.334991Z",
     "iopub.status.busy": "2023-11-13T13:53:02.334561Z",
     "iopub.status.idle": "2023-11-13T13:53:02.345109Z",
     "shell.execute_reply": "2023-11-13T13:53:02.343753Z"
    },
    "papermill": {
     "duration": 0.020598,
     "end_time": "2023-11-13T13:53:02.348018",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.327420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_dict_to_tensor(dict_):\n",
    "    \"\"\"Converts the values of a dict into a PyTorch tensor.\"\"\"\n",
    "\n",
    "    # Create a new PyTorch tensor\n",
    "    tensor = torch.empty(len(dict_))\n",
    "\n",
    "    # Iterate over the dict and for each key-value pair, convert the value to a PyTorch tensor and add it to the new tensor\n",
    "    for i, (key, value) in enumerate(dict_.items()):\n",
    "        tensor[i] = value\n",
    "\n",
    "    # Return the new tensor\n",
    "    return tensor\n",
    "\n",
    "def get_class_weights(df_train):\n",
    "    label_counts = df_train.target_label.value_counts().sort_index().to_dict()\n",
    "    ratios_dict = {}\n",
    "    for key,val in label_counts.items():\n",
    "        ratios_dict[key] = val / df_train.shape[0]\n",
    "    ratios_dict\n",
    "    weights = {}\n",
    "    sum_weights = 0\n",
    "    for key, val in ratios_dict.items():\n",
    "        weights[key] = 1 / val\n",
    "        sum_weights +=  1 / val\n",
    "    for key, val in weights.items():\n",
    "        weights[key] = val / sum_weights\n",
    "    weight_tensor = convert_dict_to_tensor(weights)\n",
    "    return weight_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48587b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T13:53:02.362258Z",
     "iopub.status.busy": "2023-11-13T13:53:02.361853Z",
     "iopub.status.idle": "2023-11-13T13:53:02.377979Z",
     "shell.execute_reply": "2023-11-13T13:53:02.376990Z"
    },
    "papermill": {
     "duration": 0.026305,
     "end_time": "2023-11-13T13:53:02.380735",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.354430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_val_dataset(model, CONFIG, df_validate, encoder, TRAIN_DIR=None, val_size=1.0):\n",
    "    \n",
    "    valid_dataset = UBCDataset(df_validate, transforms=data_transforms[\"valid\"])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                          num_workers=2, shuffle=False, pin_memory=True)\n",
    "\n",
    "    preds = []\n",
    "    labels_list = []\n",
    "    output_list = []\n",
    "    valid_acc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
    "        for step, data in bar: \n",
    "            # print(step)\n",
    "            images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)\n",
    "            labels = data['label'].to(CONFIG[\"device\"], dtype=torch.long)\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            outputs = model(images)\n",
    "            outputs = model.softmax(outputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            preds.append( predicted.detach().cpu().numpy() )\n",
    "            labels_list.append(labels.detach().cpu().numpy())\n",
    "            output_list.append(outputs.detach().cpu().numpy())\n",
    "            acc = torch.sum( predicted == labels )\n",
    "            valid_acc  += acc.item()\n",
    "    valid_acc /= len(valid_loader.dataset)\n",
    "    preds = np.concatenate(preds).flatten()\n",
    "    labels_list = np.concatenate(labels_list).flatten()\n",
    "    pred_labels = encoder.inverse_transform( preds )\n",
    "\n",
    "    # Calculate Balanced Accuracy\n",
    "    bal_acc = balanced_accuracy_score(labels_list, preds)\n",
    "    # Calculate Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(labels_list, preds)\n",
    "    macro_f1 = f1_score(labels_list, preds, average='macro')\n",
    "    micro_f1 = f1_score(labels_list, preds, average='micro')\n",
    "    weighted_f1 = f1_score(labels_list, preds, average='weighted')\n",
    "\n",
    "    print(f\"Validation Accuracy: {valid_acc}\")\n",
    "    print(f\"Balanced Accuracy: {bal_acc}\")\n",
    "    print(f\"Macro F1-Score: {macro_f1}\")\n",
    "    print(f\"Micro F1-Score: {micro_f1}\")\n",
    "    print(f\"Weighted F1-Score: {weighted_f1}\")\n",
    "    print(f\"Confusion Matrix: {conf_matrix}\")\n",
    "\n",
    "    # add to validation dataframe\n",
    "    df_validate[\"pred\"] = preds\n",
    "    df_validate[\"pred_labels\"] = pred_labels\n",
    "    return df_validate, preds, labels_list, output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1be3ad",
   "metadata": {
    "papermill": {
     "duration": 0.005372,
     "end_time": "2023-11-13T13:53:02.392147",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.386775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410868c",
   "metadata": {
    "papermill": {
     "duration": 0.00527,
     "end_time": "2023-11-13T13:53:02.403956",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.398686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b37a4a",
   "metadata": {
    "papermill": {
     "duration": 0.006098,
     "end_time": "2023-11-13T13:53:02.416156",
     "exception": false,
     "start_time": "2023-11-13T13:53:02.410058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.245053,
   "end_time": "2023-11-13T13:53:04.249967",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-13T13:52:47.004914",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
