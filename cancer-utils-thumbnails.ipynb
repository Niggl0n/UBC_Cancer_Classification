{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f46603",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:09.900075Z",
     "iopub.status.busy": "2023-11-29T17:13:09.899616Z",
     "iopub.status.idle": "2023-11-29T17:13:20.179477Z",
     "shell.execute_reply": "2023-11-29T17:13:20.178116Z"
    },
    "papermill": {
     "duration": 10.291896,
     "end_time": "2023-11-29T17:13:20.182464",
     "exception": false,
     "start_time": "2023-11-29T17:13:09.890568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torchvision\n",
    "\n",
    "from itertools import chain\n",
    "import heapq\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from skimage import io\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "from joblib.externals.loky.backend.context import get_context\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Albumentations for augmentations\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1198c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.197722Z",
     "iopub.status.busy": "2023-11-29T17:13:20.197277Z",
     "iopub.status.idle": "2023-11-29T17:13:20.204509Z",
     "shell.execute_reply": "2023-11-29T17:13:20.203114Z"
    },
    "papermill": {
     "duration": 0.018136,
     "end_time": "2023-11-29T17:13:20.207380",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.189244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"is_submission\": False,\n",
    "    \"datetime_now\": datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"), \n",
    "    \"n_fold\": 5,\n",
    "    'fold': 1,\n",
    "    'test_fold': 0,\n",
    "    \"seed\": 42,\n",
    "    \"img_size\": 512,\n",
    "    \"crop_vertical\":True,\n",
    "    \"model_name\": \"tf_efficientnetv2_s_in21ft1k\",   # \"tf_efficientnet_b0_ns\", # \"tf_efficientnetv2_s_in21ft1k\"\n",
    "    \"checkpoint_path\": \"/kaggle/input/tf-efficientnetv2-s-in21ft1k/tf_efficientnetv2_s_in21ft1k.pth\",\n",
    "    \"num_classes\": 5,\n",
    "    \"valid_batch_size\": 16,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    # \"model_path\": '/kaggle/input/efficientnetb0-training-crop-images/best_model_checkpoint2023-10-26_09-10-29.pth',\n",
    "    \"encoder_path\": \"/kaggle/input/effnet-version-28/label_encoder_2023-11-21_15-45-54.pkl\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c51111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.222352Z",
     "iopub.status.busy": "2023-11-29T17:13:20.221933Z",
     "iopub.status.idle": "2023-11-29T17:13:20.229072Z",
     "shell.execute_reply": "2023-11-29T17:13:20.227482Z"
    },
    "papermill": {
     "duration": 0.017508,
     "end_time": "2023-11-29T17:13:20.231571",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.214063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_or_create_experiment_id(name):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "        exp_id = mlflow.create_experiment(name)\n",
    "        return exp_id\n",
    "    return exp.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe6bd0",
   "metadata": {
    "papermill": {
     "duration": 0.006227,
     "end_time": "2023-11-29T17:13:20.244550",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.238323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Datasets & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20811e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.259217Z",
     "iopub.status.busy": "2023-11-29T17:13:20.258822Z",
     "iopub.status.idle": "2023-11-29T17:13:20.265271Z",
     "shell.execute_reply": "2023-11-29T17:13:20.264115Z"
    },
    "papermill": {
     "duration": 0.016902,
     "end_time": "2023-11-29T17:13:20.267925",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.251023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_file_path(df_train_row):\n",
    "    if df_train_row.is_tma == False:\n",
    "        return f\"{TRAIN_DIR}/{df_train_row.image_id}_thumbnail.png\"\n",
    "    else:\n",
    "        return f\"{TMA_TRAIN_DIR}/{df_train_row.image_id}.png\"\n",
    "\n",
    "\n",
    "def get_test_file_path(image_id):\n",
    "    if os.path.exists(f\"{TEST_DIR}/{image_id}.png\"):\n",
    "        return f\"{TEST_DIR}/{image_id}.png\"\n",
    "    else:\n",
    "        return f\"{ALT_TEST_DIR}/{image_id}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f649d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.284262Z",
     "iopub.status.busy": "2023-11-29T17:13:20.283592Z",
     "iopub.status.idle": "2023-11-29T17:13:20.298047Z",
     "shell.execute_reply": "2023-11-29T17:13:20.296828Z"
    },
    "papermill": {
     "duration": 0.026036,
     "end_time": "2023-11-29T17:13:20.300893",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.274857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UBCDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, apply_vertical_crop=True):\n",
    "        self.df = df\n",
    "        self.filenames = df.file_path.values\n",
    "        self.labels =  df.target_label.values\n",
    "        self.transforms = transforms\n",
    "        self.apply_vertical_crop = apply_vertical_crop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.filenames[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.apply_vertical_crop:\n",
    "            img = crop_vertical(img)\n",
    "                \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "               }\n",
    "\n",
    "def crop_vertical(image):\n",
    "    \"\"\"\n",
    "    Function crops images if multiple slices contained and separated by black vertical background.\n",
    "    \"\"\"\n",
    "    vertical_sum = np.sum(image, axis=(0, 2))\n",
    "\n",
    "    # Identify the positions where the sum is zero\n",
    "    zero_positions = np.where(vertical_sum == 0)[0]\n",
    "\n",
    "    if len(zero_positions)==0:\n",
    "        cropped_images = [image]\n",
    "    else:\n",
    "        # If the image does not start with a black area, add index 0\n",
    "        if zero_positions[0] != 0:\n",
    "            zero_positions = np.insert(zero_positions, 0, 0)\n",
    "\n",
    "        # If the image does not end with a black area, add the image width\n",
    "        if zero_positions[-1] != image.shape[1] - 1:\n",
    "            zero_positions = np.append(zero_positions, image.shape[1] - 1)\n",
    "\n",
    "        start_idx = zero_positions[0]\n",
    "        cropped_images = []\n",
    "\n",
    "        for idx in range(1, len(zero_positions)):\n",
    "            end_idx = zero_positions[idx]\n",
    "            if end_idx - start_idx > 1:  # If the width of the cropped section is greater than 1\n",
    "                cropped = image[:, start_idx:end_idx]\n",
    "                # only include samples which are of min size\n",
    "                if cropped.shape[1]>200:  \n",
    "                    cropped_images.append(cropped)\n",
    "                    # cv2.imwrite(f\"{save_prefix}_{idx}.jpg\", cropped)\n",
    "            start_idx = end_idx\n",
    "\n",
    "    final_crops = []\n",
    "    # remove black bars above/below the crops \n",
    "    for cropped in cropped_images:\n",
    "        horizontal_sum = np.sum(cropped, axis=(1, 2))\n",
    "        zero_positions = np.where(horizontal_sum == 0)[0]\n",
    "        img_ = np.delete(cropped, zero_positions, axis=0)\n",
    "        final_crops.append(img_)\n",
    "    if len(final_crops)==0:\n",
    "        return image\n",
    "    return final_crops[0]\n",
    "\n",
    "\n",
    "def custom_center_crop_or_resize(image, crop_size):\n",
    "    # If both dimensions of the image are greater than or equal to the desired size, apply CenterCrop\n",
    "    if image.shape[0] >= crop_size[0] and image.shape[1] >= crop_size[1]:\n",
    "        return A.CenterCrop(crop_size[0], crop_size[1])(image=image)[\"image\"]\n",
    "    # Else, just resize the image to the desired size\n",
    "    else:\n",
    "        return A.Resize(crop_size[0], crop_size[1])(image=image)[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b0e23b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.316482Z",
     "iopub.status.busy": "2023-11-29T17:13:20.316052Z",
     "iopub.status.idle": "2023-11-29T17:13:20.323117Z",
     "shell.execute_reply": "2023-11-29T17:13:20.322167Z"
    },
    "papermill": {
     "duration": 0.017163,
     "end_time": "2023-11-29T17:13:20.325130",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.307967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _color_means(img_path):\n",
    "    img = np.array(Image.open(img_path))\n",
    "    mask = np.sum(img[..., :3], axis=2) == 0\n",
    "    img[mask, :] = 255\n",
    "    if np.max(img) > 1.5:\n",
    "        img = img / 255.0\n",
    "    clr_mean = {i: np.mean(img[..., i]) for i in range(3)}\n",
    "    clr_std = {i: np.std(img[..., i]) for i in range(3)}\n",
    "    return clr_mean, clr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd2ab77a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.341275Z",
     "iopub.status.busy": "2023-11-29T17:13:20.340026Z",
     "iopub.status.idle": "2023-11-29T17:13:20.350107Z",
     "shell.execute_reply": "2023-11-29T17:13:20.349078Z"
    },
    "papermill": {
     "duration": 0.020652,
     "end_time": "2023-11-29T17:13:20.352468",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.331816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_color_mean=[0.8661704276539922, 0.7663107094675368, 0.8574260897185548]\n",
    "img_color_std=[0.08670629753900036, 0.11646580094195522, 0.07164169171856792]\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(512, 512),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "        A.GaussNoise(var_limit=[10, 50]),\n",
    "        A.GaussianBlur(),\n",
    "        A.MotionBlur(),\n",
    "        ], p=0.4),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(512* 0.3), max_height=int(512* 0.3),\n",
    "        mask_fill_value=0, p=0.5),\n",
    "        A.Normalize(img_color_mean, img_color_std), \n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(img_color_mean, img_color_std), \n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419c612",
   "metadata": {
    "papermill": {
     "duration": 0.006501,
     "end_time": "2023-11-29T17:13:20.365575",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.359074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "005edb59",
   "metadata": {
    "papermill": {
     "duration": 0.007102,
     "end_time": "2023-11-29T17:13:20.379765",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.372663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2. Tiles Dataset\n",
    "\n",
    "### 2.2.1. Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c9674a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.395494Z",
     "iopub.status.busy": "2023-11-29T17:13:20.394803Z",
     "iopub.status.idle": "2023-11-29T17:13:20.409731Z",
     "shell.execute_reply": "2023-11-29T17:13:20.408780Z"
    },
    "papermill": {
     "duration": 0.025678,
     "end_time": "2023-11-29T17:13:20.412231",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.386553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CancerTilesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_data,\n",
    "        path_img_dir: str =  '',\n",
    "        transforms = None,\n",
    "        mode: str = 'train',\n",
    "        labels_lut = None,\n",
    "        white_thr: int = 225,\n",
    "        thr_max_bg: float = 0.2,\n",
    "        split: float = 0.90,\n",
    "        n_tiles: int = 1\n",
    "    ):\n",
    "        assert os.path.isdir(path_img_dir)\n",
    "        self.path_img_dir = path_img_dir\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.white_thr = white_thr\n",
    "        self.thr_max_bg = thr_max_bg\n",
    "        self.split = split\n",
    "        self.n_tiles = n_tiles\n",
    "\n",
    "        self.data = df_data\n",
    "        self.labels_unique = sorted(self.data[\"label\"].unique())\n",
    "        self.labels_lut = labels_lut or {lb: i for i, lb in enumerate(self.labels_unique)}\n",
    "        # shuffle data\n",
    "        self.data = self.data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        # split dataset\n",
    "        assert 0.0 <= self.split <= 1.0\n",
    "        frac = int(self.split * len(self.data))\n",
    "        self.data = self.data[:frac] if mode in [\"train\", \"test\"] else self.data[frac:]\n",
    "        self.img_dirs = [glob.glob(os.path.join(path_img_dir, str(idx), \"*.png\")) for idx in self.data[\"image_id\"]] \n",
    "        self.img_dirs = self.img_dirs * self.n_tiles\n",
    "        self.img_paths = []\n",
    "        #print(f\"missing: {sum([not os.path.isfile(os.path.join(self.path_img_dir, im))\n",
    "        #                       for im in self.img_names])}\")\n",
    "        # self.labels = list(self.data['label'])\n",
    "        self.labels =  np.array(self.data.target_label.values.tolist() * self.n_tiles)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        nth_iteration = idx//len(self.data)\n",
    "        if self.mode==\"train\":\n",
    "            random.seed()\n",
    "        else:\n",
    "            random.seed(CONFIG[\"seed\"]+nth_iteration)\n",
    "        random.shuffle(self.img_dirs[idx])\n",
    "        for img_path in self.img_dirs[idx]:\n",
    "            assert os.path.isfile(img_path), f\"missing: {img_path}\"\n",
    "            tile = cv2.imread(img_path)\n",
    "            tile = cv2.cvtColor(tile, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            # tile = np.array(Image.open(img_path))[..., :3]\n",
    "            black_bg = np.sum(tile, axis=2) == 0\n",
    "            tile[black_bg, :] = 255\n",
    "            mask_bg = np.mean(tile, axis=2) > self.white_thr\n",
    "            if np.sum(mask_bg) < (np.prod(mask_bg.shape) * self.thr_max_bg):\n",
    "                #self.img_paths.append(img_path)\n",
    "                #print(f\"Idx: {idx}, Path: {img_path}, len img_pths: {len(self.img_paths)}, nunique img_paths: {len(set(self.img_paths))}\")\n",
    "                break\n",
    "\n",
    "        # augmentation\n",
    "        if self.transforms:\n",
    "            tile = self.transforms(image=tile)[\"image\"]\n",
    "        #print(f\"img dim: {img.shape}\")\n",
    "        return {\n",
    "            \"image\": tile,\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "               }\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d00587",
   "metadata": {
    "papermill": {
     "duration": 0.007508,
     "end_time": "2023-11-29T17:13:20.426587",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.419079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85831318",
   "metadata": {
    "papermill": {
     "duration": 0.006446,
     "end_time": "2023-11-29T17:13:20.439926",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.433480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.2.2 Inference Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a73d5537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.455556Z",
     "iopub.status.busy": "2023-11-29T17:13:20.454872Z",
     "iopub.status.idle": "2023-11-29T17:13:20.475813Z",
     "shell.execute_reply": "2023-11-29T17:13:20.474815Z"
    },
    "papermill": {
     "duration": 0.031695,
     "end_time": "2023-11-29T17:13:20.478284",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.446589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_tiles(directory_path):\n",
    "    if os.path.isdir(directory_path):\n",
    "        for filename in os.listdir(directory_path):\n",
    "            if os.path.isfile(os.path.join(directory_path, filename)):\n",
    "                os.remove(os.path.join(directory_path, filename))\n",
    "\n",
    "def extract_image_tiles(\n",
    "    p_img, img_id, tmp_dir, size: int = 2048, scale: float = 0.5,\n",
    "    drop_thr: float = 0.8, white_thr: int = 245, max_samples: int = 50\n",
    ") -> list:\n",
    "    delete_tiles(tmp_dir)  # empty directory from previous images\n",
    "    im = pyvips.Image.new_from_file(p_img)\n",
    "    w = h = size\n",
    "    # https://stackoverflow.com/a/47581978/4521646\n",
    "    idxs = [(y, y + h, x, x + w) for y in range(0, im.height, h) for x in range(0, im.width, w)]\n",
    "    # random subsample\n",
    "    max_samples = max_samples if isinstance(max_samples, int) else int(len(idxs) * max_samples)\n",
    "    random.seed(42)\n",
    "    random.shuffle(idxs)\n",
    "    images = []\n",
    "    i = 0\n",
    "    for y, y_, x, x_ in (idxs):\n",
    "        i += 1\n",
    "        img_path = f\"{tmp_dir}/{str(i)}.png\"\n",
    "        # https://libvips.github.io/pyvips/vimage.html#pyvips.Image.crop\n",
    "        tile = im.crop(x, y, min(w, im.width - x), min(h, im.height - y)).numpy()[..., :3]\n",
    "        if tile.shape[:2] != (h, w):\n",
    "            tile_ = tile\n",
    "            tile_size = (h, w) if tile.ndim == 2 else (h, w, tile.shape[2])\n",
    "            tile = np.zeros(tile_size, dtype=tile.dtype)\n",
    "            tile[:tile_.shape[0], :tile_.shape[1], ...] = tile_\n",
    "        black_bg = np.sum(tile, axis=2) == 0\n",
    "        tile[black_bg, :] = 255\n",
    "        mask_bg = np.mean(tile, axis=2) > white_thr\n",
    "        if np.sum(mask_bg) >= (np.prod(mask_bg.shape) * drop_thr):\n",
    "            #print(f\"skip almost empty tile: {k:06}_{int(x_ / w)}-{int(y_ / h)}\")\n",
    "            continue\n",
    "        # print(tile.shape, tile.dtype, tile.min(), tile.max())\n",
    "        new_size = int(size * scale), int(size * scale)\n",
    "        tile = Image.fromarray(tile).resize(new_size, Image.LANCZOS)\n",
    "        tile.save(img_path)\n",
    "        images.append(img_path)\n",
    "        # need to set counter check as some empty tiles could be skipped earlier\n",
    "        if len(images) >= max_samples:\n",
    "            break\n",
    "    return images\n",
    "\n",
    "\n",
    "class TilesInferenceDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_path: str,\n",
    "        img_id: str = None,\n",
    "        tmp_dir: str = None,\n",
    "        size: int = 2048,\n",
    "        scale: float = 0.25,\n",
    "        white_thr: int = 225,\n",
    "        thr_max_bg: float = 0.6,\n",
    "        max_samples: int = 30,\n",
    "        transforms = None,\n",
    "        is_submission: bool = True,\n",
    "    ):\n",
    "        self.max_samples = max_samples\n",
    "        self.white_thr = white_thr\n",
    "        self.thr_max_bg = thr_max_bg\n",
    "        self.is_submission = is_submission\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        if self.is_submission:\n",
    "            # print(img_path)\n",
    "            assert os.path.isfile(img_path)\n",
    "            self.imgs = extract_image_tiles(\n",
    "                img_path, img_id, tmp_dir, size=size, scale=scale,\n",
    "                drop_thr=self.thr_max_bg, max_samples=max_samples)\n",
    "        else:  # test\n",
    "            all_imgs = glob.glob(os.path.join(img_path, img_id, \"*.png\"))\n",
    "            # Filter images based on background threshold\n",
    "            self.imgs = []\n",
    "            for img_path in all_imgs:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                black_bg = np.sum(img, axis=2) == 0\n",
    "                img[black_bg, :] = 255\n",
    "                mask_bg = np.mean(img, axis=2) > self.white_thr\n",
    "                if np.sum(mask_bg) <= (np.prod(mask_bg.shape) * self.thr_max_bg):\n",
    "                    self.imgs.append(img_path)  # Include this image\n",
    "            self.imgs = self.imgs[:self.max_samples]\n",
    "            # print(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        img = cv2.imread(self.imgs[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # filter background\n",
    "        mask = np.sum(img, axis=2) == 0\n",
    "        img[mask, :] = 255\n",
    "        if np.max(img) < 1.5:\n",
    "            img = np.clip(img * 255, 0, 255).astype(np.uint8)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "        return img\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b17ba17a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.493872Z",
     "iopub.status.busy": "2023-11-29T17:13:20.493448Z",
     "iopub.status.idle": "2023-11-29T17:13:20.500409Z",
     "shell.execute_reply": "2023-11-29T17:13:20.499088Z"
    },
    "papermill": {
     "duration": 0.01747,
     "end_time": "2023-11-29T17:13:20.502632",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.485162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(df, fold, CONFIG):\n",
    "    df_train = df[df[\"kfold\"]!=fold].reset_index(drop=True)\n",
    "    df_valid = df[df[\"kfold\"]==fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = UBCDataset(df_train, transforms=data_transforms[\"train\"])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    valid_dataset = UBCDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    return train_loader, valid_loader, df_train, df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904f624",
   "metadata": {
    "papermill": {
     "duration": 0.00655,
     "end_time": "2023-11-29T17:13:20.516452",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.509902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "321e2247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.531979Z",
     "iopub.status.busy": "2023-11-29T17:13:20.531505Z",
     "iopub.status.idle": "2023-11-29T17:13:20.543940Z",
     "shell.execute_reply": "2023-11-29T17:13:20.542603Z"
    },
    "papermill": {
     "duration": 0.023183,
     "end_time": "2023-11-29T17:13:20.546409",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.523226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class UBCModel(nn.Module):\n",
    "    '''\n",
    "    EfficientNet B0 fine-tune.\n",
    "    '''\n",
    "    def __init__(self, model_name, num_classes, pretrained=False, checkpoint_path=None):\n",
    "        '''\n",
    "        Fine tune for EfficientNetB0\n",
    "        Args\n",
    "            n_classes : int - Number of classification categories.\n",
    "            learnable_modules : tuple - Names of the modules to fine-tune.\n",
    "        Return\n",
    "            \n",
    "        '''\n",
    "        super(UBCModel, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward function for the fine-tuned model\n",
    "        Args\n",
    "            x: \n",
    "        Return\n",
    "            result\n",
    "        \"\"\"\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        output = self.linear(pooled_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62df8fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.562419Z",
     "iopub.status.busy": "2023-11-29T17:13:20.561531Z",
     "iopub.status.idle": "2023-11-29T17:13:20.571412Z",
     "shell.execute_reply": "2023-11-29T17:13:20.570106Z"
    },
    "papermill": {
     "duration": 0.020519,
     "end_time": "2023-11-29T17:13:20.573936",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.553417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df08865",
   "metadata": {
    "papermill": {
     "duration": 0.006416,
     "end_time": "2023-11-29T17:13:20.587211",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.580795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8277f4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.602813Z",
     "iopub.status.busy": "2023-11-29T17:13:20.602340Z",
     "iopub.status.idle": "2023-11-29T17:13:20.616102Z",
     "shell.execute_reply": "2023-11-29T17:13:20.615113Z"
    },
    "papermill": {
     "duration": 0.024197,
     "end_time": "2023-11-29T17:13:20.618389",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.594192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'], verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        CONFIG['T_0'] = 10\n",
    "        CONFIG['T_mult'] = 2\n",
    "        CONFIG['min_lr'] = 1e-6\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG['T_0'], T_mult=CONFIG['T_mult'],\n",
    "                                                             eta_min=CONFIG['min_lr'], verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'ReduceLROnPlateau':\n",
    "        scheduler =  ReduceLROnPlateau(optimizer, mode='min', factor=kwargs.get('factor', 0.1), patience=kwargs.get('patience', 5), verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'LambdaLR':\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "def get_optimizer(optimizer_name, model):\n",
    "    if optimizer_name.lower() == \"adam\":\n",
    "        CONFIG['learning_rate'] = 1e-4\n",
    "        CONFIG['weight_decay'] = 1e-5\n",
    "        CONFIG['betas'] = (0.9, 0.999)\n",
    "        CONFIG['eps'] = 1e-8\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], betas=CONFIG['betas'], eps=CONFIG['eps'],  weight_decay=CONFIG['weight_decay'])\n",
    "    elif optimizer_name.lower() == \"sgd\":\n",
    "        CONFIG['learning_rate'] = 1e-3\n",
    "        CONFIG['weight_decay'] = 1e-3\n",
    "        CONFIG['momentum'] = 1e-3\n",
    "        optimizer = optim.SGD(model.parameters(), lr=CONFIG['learning_rate'], momentum=CONFIG['momentum'], weight_decay=CONFIG['weight_decay'])\n",
    "    elif optimizer_name.lower() == \"radam\":\n",
    "        CONFIG['learning_rate'] = 1e-4\n",
    "        CONFIG['weight_decay'] = 0\n",
    "        CONFIG['betas'] = (0.9, 0.999)\n",
    "        CONFIG['eps'] = 1e-8\n",
    "        optimizer = torch_optimizer.RAdam(\n",
    "            model.parameters(),\n",
    "            lr= CONFIG['learning_rate'],\n",
    "            betas=CONFIG['betas'],\n",
    "            eps=CONFIG['eps'],\n",
    "            weight_decay=CONFIG['weight_decay'],\n",
    "        )\n",
    "    elif optimizer_name.lower() == \"rmsprop\":\n",
    "        CONFIG['learning_rate'] = 0.256\n",
    "        CONFIG['alpha'] = 0.9\n",
    "        CONFIG['momentum'] = 0.9\n",
    "        CONFIG['weight_decay'] = 1e-5\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=CONFIG['learning_rate'], alpha=CONFIG['learning_rate'], \n",
    "                                  momentum=CONFIG['learning_rate'], weight_decay=CONFIG['learning_rate'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Optimizer given!\")\n",
    "    return optimizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d2bd02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.634830Z",
     "iopub.status.busy": "2023-11-29T17:13:20.634090Z",
     "iopub.status.idle": "2023-11-29T17:13:20.645998Z",
     "shell.execute_reply": "2023-11-29T17:13:20.645057Z"
    },
    "papermill": {
     "duration": 0.023142,
     "end_time": "2023-11-29T17:13:20.648516",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.625374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_dict_to_tensor(dict_):\n",
    "    \"\"\"Converts the values of a dict into a PyTorch tensor.\"\"\"\n",
    "\n",
    "    # Create a new PyTorch tensor\n",
    "    tensor = torch.empty(len(dict_))\n",
    "\n",
    "    # Iterate over the dict and for each key-value pair, convert the value to a PyTorch tensor and add it to the new tensor\n",
    "    for i, (key, value) in enumerate(dict_.items()):\n",
    "        tensor[i] = value\n",
    "\n",
    "    # Return the new tensor\n",
    "    return tensor\n",
    "\n",
    "def get_class_weights(df_train):\n",
    "    label_counts = df_train.target_label.value_counts().sort_index().to_dict()\n",
    "    ratios_dict = {}\n",
    "    for key,val in label_counts.items():\n",
    "        ratios_dict[key] = val / df_train.shape[0]\n",
    "    ratios_dict\n",
    "    weights = {}\n",
    "    sum_weights = 0\n",
    "    for key, val in ratios_dict.items():\n",
    "        weights[key] = 1 / val\n",
    "        sum_weights +=  1 / val\n",
    "    for key, val in weights.items():\n",
    "        weights[key] = val / sum_weights\n",
    "    weight_tensor = convert_dict_to_tensor(weights)\n",
    "    return weight_tensor\n",
    "\n",
    "def get_dataloaders(df, n_tiles=1):\n",
    "    # df_train = df[df[\"kfold\"]!=fold].reset_index(drop=True)\n",
    "    train_dataset = CancerTilesDataset(df_train, TRAIN_DIR, transforms=data_transforms[\"train\"], mode=\"train\", n_tiles=n_tiles)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    valid_dataset = CancerTilesDataset(df_train, TRAIN_DIR, transforms=data_transforms[\"valid\"], mode=\"valid\", n_tiles=n_tiles)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    print(f\"Len Train Dataset: {len(train_dataset)}, Len Validation Dataset: {len(valid_dataset)}\" )\n",
    "    return train_loader, valid_loader, df_train\n",
    "\n",
    "def print_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(f\"run_id: {r.info.run_id}\")\n",
    "    print(f\"artifacts: {artifacts}\")\n",
    "    print(f\"params: {r.data.params}\")\n",
    "    print(f\"metrics: {r.data.metrics}\")\n",
    "    print(f\"tags: {tags}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968bc73",
   "metadata": {
    "papermill": {
     "duration": 0.006285,
     "end_time": "2023-11-29T17:13:20.661588",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.655303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4eebbe0",
   "metadata": {
    "papermill": {
     "duration": 0.006206,
     "end_time": "2023-11-29T17:13:20.674298",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.668092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Inference & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e85050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.690206Z",
     "iopub.status.busy": "2023-11-29T17:13:20.689275Z",
     "iopub.status.idle": "2023-11-29T17:13:20.700312Z",
     "shell.execute_reply": "2023-11-29T17:13:20.699008Z"
    },
    "papermill": {
     "duration": 0.021652,
     "end_time": "2023-11-29T17:13:20.702990",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.681338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_predictions(df):\n",
    "    # Total Accuracy\n",
    "    total_accuracy = accuracy_score(df['target_label'], df['label'])\n",
    "\n",
    "    # Balanced Accuracy\n",
    "    balanced_accuracy = balanced_accuracy_score(df['target_label'], df['label'])\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(df['target_label'], df['label'], average='weighted')\n",
    "\n",
    "    # Accuracy Per Class\n",
    "    cm = confusion_matrix(df['target_label'], df['label'])\n",
    "    class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    print(f\"Total Accuracy: {total_accuracy}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Accuracy Per Class: {class_accuracy}\")\n",
    "    display(cm)\n",
    "    \n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "def score_predictions(preds, method=\"sum\", N=10):\n",
    "    if method==\"sum\":  # sum up the predictions of all tiles/models\n",
    "        lb = np.argmax(np.sum(preds, axis=0))\n",
    "    elif method in [\"most_frequent\", \"most_votes\", \"majority_vote\"]:  # get majority vote over all tiles/models \n",
    "        lb = most_frequent(np.argmax(preds, axis=1).tolist())\n",
    "    elif method == \"n_highest_sum\":  # sum up predictions of N-most decicive tiles/models\n",
    "        max_vals = np.max(preds, axis=1).tolist()\n",
    "        max_idxs = [max_vals.index(i) for i in heapq.nlargest(N, max_vals)]\n",
    "        n_tiles_preds = np.take(preds, max_idxs, axis=0).tolist()\n",
    "        lb = np.argmax(np.sum(n_tiles_preds, axis=0))\n",
    "    else:\n",
    "        print(\"No method found: Apply Sum Method for Scoring predictions!\")\n",
    "        lb = np.argmax(np.sum(preds, axis=0))\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b9b7d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T17:13:20.719009Z",
     "iopub.status.busy": "2023-11-29T17:13:20.718577Z",
     "iopub.status.idle": "2023-11-29T17:13:20.736115Z",
     "shell.execute_reply": "2023-11-29T17:13:20.734754Z"
    },
    "papermill": {
     "duration": 0.028973,
     "end_time": "2023-11-29T17:13:20.738625",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.709652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_with_softmax(model, images):\n",
    "    with torch.no_grad():\n",
    "        logits = model(images)\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        return probabilities\n",
    "    \n",
    "def apply_thr_outlier_detect(predictions, label, threshold = 0.60):\n",
    "    # Convert logits to probabilities\n",
    "    probabilities = softmax(predictions)\n",
    "\n",
    "    # Apply the threshold\n",
    "    max_probabilities = np.max(probabilities)\n",
    "    if max_probabilities < threshold:\n",
    "        print(\"Outlier detected:\", max_probabilities)\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return label\n",
    "    \n",
    "def infer_single_image_ensemble(idx_row, models, CONFIG, encoder, score_method=\"sum\", max_samples=30, thr_max_bg=0.1, is_submission=True, device=\"cuda\") -> dict:\n",
    "    \"\"\"\n",
    "    Create tiled-dataset based on test image.\n",
    "    Iterate throuh all tiles and apply model prediction.\n",
    "    Select highest of sum of all logits.\n",
    "    \"\"\"\n",
    "    row = dict(idx_row[1])\n",
    "    img_id = str(row[\"image_id\"])\n",
    "    result = {\"image_id\": img_id}\n",
    "    tmp_dir = \"tmp_tiles_\"+str(img_id)\n",
    "    print(\"Image ID: \", img_id)\n",
    "    if is_submission:\n",
    "        result[\"target_label\"] = encoder.inverse_transform(np.array(row[\"target_label\"]).ravel())[0]\n",
    "        # delete old directory if exists and create new empty directory to temporarily save image tiles   \n",
    "        if os.path.exists(tmp_dir) and os.path.isdir(tmp_dir):\n",
    "            shutil.rmtree(tmp_dir)\n",
    "        os.mkdir(tmp_dir)  \n",
    "        dataset = TilesInferenceDataset(\n",
    "            os.path.join(\"/kaggle/input/UBC-OCEAN/\", \"train_images\", f\"{img_id}.png\"), tmp_dir=tmp_dir, \n",
    "            size=2048, scale=0.25, thr_max_bg=thr_max_bg, transforms=data_transforms[\"valid\"], max_samples=max_samples)\n",
    "    else:\n",
    "        dataset = TilesInferenceDataset(\n",
    "            \"/kaggle/input/tiles-of-cancer-2048px-scale-0-25\", img_id,\n",
    "            size=2048, scale=0.25, thr_max_bg=thr_max_bg, transforms=data_transforms[\"valid\"], is_submission=is_submission, max_samples=max_samples)\n",
    "        result[\"target_label\"] = encoder.inverse_transform(np.array(row[\"target_label\"]).ravel())[0]\n",
    "        \n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=CONFIG[\"valid_batch_size\"], num_workers=2, shuffle=False,\n",
    "        multiprocessing_context=get_context('loky')         # see: https://github.com/pytorch/pytorch/issues/44687#issuecomment-790842173\n",
    "    )\n",
    "    if not len(dataset):  # if no tiles available, set to \"Other\" class\n",
    "        if not is_submission: \n",
    "            print (f\"seem no tiles were cut for `{row['image_id']}`. Set to label Other\")\n",
    "        result[\"label\"] = \"Other\"\n",
    "        return result\n",
    "    \n",
    "    if not isinstance(models, list):\n",
    "        models = [models]\n",
    "    \n",
    "    model_preds_sum = []\n",
    "    for i,model in enumerate(models):\n",
    "        #print(f\"Apply Model {i+1} of {len(models)}\")\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for imgs in dataloader:\n",
    "            # print(f\"{imgs.shape}\")\n",
    "            probabilities = infer_with_softmax(model, imgs.to(device))\n",
    "            preds += probabilities.cpu().numpy().tolist()\n",
    "        if not is_submission:\n",
    "            print(f\"Sum contrinution from all tiles: {np.sum(preds, axis=0)}\")\n",
    "            print(f\"Max contribution over all tiles: {np.max(preds, axis=0)}\")\n",
    "        model_preds_sum.append(preds)\n",
    "        \n",
    "    model_preds_sum = sum(model_preds_sum, [])\n",
    "    prediction = score_predictions(model_preds_sum, method=score_method)\n",
    "    \n",
    "    result[\"label\"] = encoder.inverse_transform(np.array(prediction).reshape(-1,))[0]        \n",
    "    result[\"label\"] = apply_thr_outlier_detect(prediction, result[\"label\"], threshold=0.6)\n",
    "    result[\"predictions\"] = np.sum(model_preds_sum, axis=0).tolist()    \n",
    "    if os.path.exists(tmp_dir) and os.path.isdir(tmp_dir):\n",
    "        shutil.rmtree(tmp_dir)\n",
    "    \n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ceaed6",
   "metadata": {
    "papermill": {
     "duration": 0.006553,
     "end_time": "2023-11-29T17:13:20.752153",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.745600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd8861",
   "metadata": {
    "papermill": {
     "duration": 0.006476,
     "end_time": "2023-11-29T17:13:20.765410",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.758934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de16896",
   "metadata": {
    "papermill": {
     "duration": 0.006385,
     "end_time": "2023-11-29T17:13:20.778609",
     "exception": false,
     "start_time": "2023-11-29T17:13:20.772224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6924515,
     "sourceId": 45867,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.118256,
   "end_time": "2023-11-29T17:13:22.310284",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-29T17:13:06.192028",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
