{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c9d791",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:30.833442Z",
     "iopub.status.busy": "2023-12-07T09:50:30.832641Z",
     "iopub.status.idle": "2023-12-07T09:50:30.848204Z",
     "shell.execute_reply": "2023-12-07T09:50:30.846904Z"
    },
    "papermill": {
     "duration": 0.029664,
     "end_time": "2023-12-07T09:50:30.850668",
     "exception": false,
     "start_time": "2023-12-07T09:50:30.821004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install --quiet mlflow dagshub\\n\\nimport mlflow\\nfrom mlflow import MlflowClient\\nimport mlflow.pytorch \\nimport dagshub'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install --quiet mlflow dagshub\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import mlflow.pytorch \n",
    "import dagshub\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946d5388",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:30.871354Z",
     "iopub.status.busy": "2023-12-07T09:50:30.870830Z",
     "iopub.status.idle": "2023-12-07T09:50:41.912495Z",
     "shell.execute_reply": "2023-12-07T09:50:41.910985Z"
    },
    "papermill": {
     "duration": 11.055764,
     "end_time": "2023-12-07T09:50:41.915634",
     "exception": false,
     "start_time": "2023-12-07T09:50:30.859870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torchvision\n",
    "\n",
    "from itertools import chain\n",
    "import heapq\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from skimage import io\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "from joblib.externals.loky.backend.context import get_context\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Albumentations for augmentations\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c941306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:41.937124Z",
     "iopub.status.busy": "2023-12-07T09:50:41.936686Z",
     "iopub.status.idle": "2023-12-07T09:50:41.944284Z",
     "shell.execute_reply": "2023-12-07T09:50:41.942937Z"
    },
    "papermill": {
     "duration": 0.021628,
     "end_time": "2023-12-07T09:50:41.946880",
     "exception": false,
     "start_time": "2023-12-07T09:50:41.925252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"is_submission\": False,\n",
    "    \"datetime_now\": datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"), \n",
    "    \"n_fold\": 5,\n",
    "    'fold': 1,\n",
    "    'test_fold': 0,\n",
    "    \"seed\": 42,\n",
    "    \"img_size\": 512,\n",
    "    \"crop_vertical\":True,\n",
    "    \"model_name\": \"tf_efficientnetv2_s_in21ft1k\",   # \"tf_efficientnet_b0_ns\", # \"tf_efficientnetv2_s_in21ft1k\"\n",
    "    \"checkpoint_path\": \"/kaggle/input/tf-efficientnetv2-s-in21ft1k/tf_efficientnetv2_s_in21ft1k.pth\",\n",
    "    \"num_classes\": 5,\n",
    "    \"valid_batch_size\": 16,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    # \"model_path\": '/kaggle/input/efficientnetb0-training-crop-images/best_model_checkpoint2023-10-26_09-10-29.pth',\n",
    "    \"encoder_path\": \"/kaggle/input/effnet-version-28/label_encoder_2023-11-21_15-45-54.pkl\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277b5013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:41.969241Z",
     "iopub.status.busy": "2023-12-07T09:50:41.968159Z",
     "iopub.status.idle": "2023-12-07T09:50:41.974455Z",
     "shell.execute_reply": "2023-12-07T09:50:41.973233Z"
    },
    "papermill": {
     "duration": 0.020559,
     "end_time": "2023-12-07T09:50:41.977208",
     "exception": false,
     "start_time": "2023-12-07T09:50:41.956649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_or_create_experiment_id(name):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "        exp_id = mlflow.create_experiment(name)\n",
    "        return exp_id\n",
    "    return exp.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422cf60f",
   "metadata": {
    "papermill": {
     "duration": 0.00927,
     "end_time": "2023-12-07T09:50:41.996055",
     "exception": false,
     "start_time": "2023-12-07T09:50:41.986785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Datasets & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a61620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.018733Z",
     "iopub.status.busy": "2023-12-07T09:50:42.018337Z",
     "iopub.status.idle": "2023-12-07T09:50:42.025697Z",
     "shell.execute_reply": "2023-12-07T09:50:42.024434Z"
    },
    "papermill": {
     "duration": 0.021386,
     "end_time": "2023-12-07T09:50:42.028270",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.006884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_file_path(df_train_row, TRAIN_DIR, thumbnail=False):\n",
    "    if thumbnail:\n",
    "        return f\"{TRAIN_DIR}/{df_train_row.image_id}_thumbnail.png\"\n",
    "    else:\n",
    "        return f\"{TRAIN_DIR}/{df_train_row.image_id}.png\"\n",
    "\n",
    "\n",
    "def get_test_file_path(image_id,TEST_DIR):\n",
    "    if os.path.exists(f\"{TEST_DIR}/{image_id}.png\"):\n",
    "        return f\"{TEST_DIR}/{image_id}.png\"\n",
    "    else:\n",
    "        return f\"{ALT_TEST_DIR}/{image_id}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab83137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.049959Z",
     "iopub.status.busy": "2023-12-07T09:50:42.049516Z",
     "iopub.status.idle": "2023-12-07T09:50:42.069319Z",
     "shell.execute_reply": "2023-12-07T09:50:42.068078Z"
    },
    "papermill": {
     "duration": 0.033997,
     "end_time": "2023-12-07T09:50:42.072032",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.038035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UBCDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, apply_vertical_crop=True):\n",
    "        self.df = df\n",
    "        self.filenames = df.file_path.values\n",
    "        self.labels =  df.target_label.values\n",
    "        self.transforms = transforms\n",
    "        self.apply_vertical_crop = apply_vertical_crop\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.filenames[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.apply_vertical_crop:\n",
    "            img = crop_vertical(img)\n",
    "                \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "               }\n",
    "\n",
    "def crop_vertical(image):\n",
    "    \"\"\"\n",
    "    Function crops images if multiple slices contained and separated by black vertical background.\n",
    "    \"\"\"\n",
    "    vertical_sum = np.sum(image, axis=(0, 2))\n",
    "\n",
    "    # Identify the positions where the sum is zero\n",
    "    zero_positions = np.where(vertical_sum == 0)[0]\n",
    "\n",
    "    if len(zero_positions)==0:\n",
    "        cropped_images = [image]\n",
    "    else:\n",
    "        # If the image does not start with a black area, add index 0\n",
    "        if zero_positions[0] != 0:\n",
    "            zero_positions = np.insert(zero_positions, 0, 0)\n",
    "\n",
    "        # If the image does not end with a black area, add the image width\n",
    "        if zero_positions[-1] != image.shape[1] - 1:\n",
    "            zero_positions = np.append(zero_positions, image.shape[1] - 1)\n",
    "\n",
    "        start_idx = zero_positions[0]\n",
    "        cropped_images = []\n",
    "\n",
    "        for idx in range(1, len(zero_positions)):\n",
    "            end_idx = zero_positions[idx]\n",
    "            if end_idx - start_idx > 1:  # If the width of the cropped section is greater than 1\n",
    "                cropped = image[:, start_idx:end_idx]\n",
    "                # only include samples which are of min size\n",
    "                if cropped.shape[1]>200:  \n",
    "                    cropped_images.append(cropped)\n",
    "                    # cv2.imwrite(f\"{save_prefix}_{idx}.jpg\", cropped)\n",
    "            start_idx = end_idx\n",
    "\n",
    "    final_crops = []\n",
    "    # remove black bars above/below the crops \n",
    "    for cropped in cropped_images:\n",
    "        horizontal_sum = np.sum(cropped, axis=(1, 2))\n",
    "        zero_positions = np.where(horizontal_sum == 0)[0]\n",
    "        img_ = np.delete(cropped, zero_positions, axis=0)\n",
    "        final_crops.append(img_)\n",
    "    if len(final_crops)==0:\n",
    "        return image\n",
    "    return final_crops[0]\n",
    "\n",
    "\n",
    "def custom_center_crop_or_resize(image, crop_size):\n",
    "    # If both dimensions of the image are greater than or equal to the desired size, apply CenterCrop\n",
    "    if image.shape[0] >= crop_size[0] and image.shape[1] >= crop_size[1]:\n",
    "        return A.CenterCrop(crop_size[0], crop_size[1])(image=image)[\"image\"]\n",
    "    # Else, just resize the image to the desired size\n",
    "    else:\n",
    "        return A.Resize(crop_size[0], crop_size[1])(image=image)[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205e9aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.094000Z",
     "iopub.status.busy": "2023-12-07T09:50:42.093543Z",
     "iopub.status.idle": "2023-12-07T09:50:42.106670Z",
     "shell.execute_reply": "2023-12-07T09:50:42.105710Z"
    },
    "papermill": {
     "duration": 0.02716,
     "end_time": "2023-12-07T09:50:42.108941",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.081781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        \\nA.Normalize(\\n    mean=[0.485, 0.456, 0.406], \\n    std=[0.229, 0.224, 0.225], \\n    max_pixel_value=255.0, \\n    p=1.0\\n),\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _color_means(img_path):\n",
    "    img = np.array(Image.open(img_path))\n",
    "    mask = np.sum(img[..., :3], axis=2) == 0\n",
    "    img[mask, :] = 255\n",
    "    if np.max(img) > 1.5:\n",
    "        img = img / 255.0\n",
    "    clr_mean = {i: np.mean(img[..., i]) for i in range(3)}\n",
    "    clr_std = {i: np.std(img[..., i]) for i in range(3)}\n",
    "    return clr_mean, clr_std\n",
    "\n",
    "\"\"\"\n",
    "ls_images = glob.glob(os.path.join(TRAIN_DIR, \"*\", \"*.png\"))\n",
    "clr_mean_std = Parallel(n_jobs=os.cpu_count())(delayed(_color_means)(fn) for fn in tqdm(ls_images[:9000]))\n",
    "\n",
    "img_color_mean = pd.DataFrame([c[0] for c in clr_mean_std]).describe()\n",
    "display(img_color_mean.T)\n",
    "img_color_std = pd.DataFrame([c[1] for c in clr_mean_std]).describe()\n",
    "display(img_color_std.T)\n",
    "\n",
    "img_color_mean = list(img_color_mean.T[\"mean\"])\n",
    "img_color_std = list(img_color_std.T[\"mean\"])\n",
    "print(f\"{img_color_mean=}\\n{img_color_std=}\")\n",
    "\"\"\"\n",
    "\n",
    "## histogram matching \n",
    "#from skimage.exposure import match_histograms\n",
    "#ref_img = np.array(Image.open(\"/kaggle/input/tiles-of-cancer-2048px-scale-0-25/10077/000067_16-3.png\"))\n",
    "#bef_img = np.array(Image.open(\"/kaggle/input/tiles-of-cancer-2048px-scale-0-25/12522/000028_6-2.png\"))\n",
    "#start = time.time()\n",
    "#aft_img = match_histograms(bef_img, ref_img, channel_axis=-1)\n",
    "#print(time.time()-start)\n",
    "\n",
    "\n",
    "\"\"\"        \n",
    "A.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], \n",
    "    std=[0.229, 0.224, 0.225], \n",
    "    max_pixel_value=255.0, \n",
    "    p=1.0\n",
    "),\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c3997a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.131078Z",
     "iopub.status.busy": "2023-12-07T09:50:42.130033Z",
     "iopub.status.idle": "2023-12-07T09:50:42.138693Z",
     "shell.execute_reply": "2023-12-07T09:50:42.137850Z"
    },
    "papermill": {
     "duration": 0.022671,
     "end_time": "2023-12-07T09:50:42.141425",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.118754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_transforms = {\\n    \"train\": A.Compose([\\n        A.Resize(CONFIG[\\'img_size\\'], CONFIG[\\'img_size\\']),\\n        A.HorizontalFlip(p=0.5),\\n        A.VerticalFlip(p=0.5),\\n        A.RandomBrightnessContrast(p=0.75),\\n        A.ShiftScaleRotate(p=0.75),\\n        A.OneOf([\\n        A.GaussNoise(var_limit=[10, 50]),\\n        A.GaussianBlur(),\\n        A.MotionBlur(),\\n        ], p=0.4),\\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\\n        A.CoarseDropout(max_holes=1, max_width=int(512* 0.3), max_height=int(512* 0.3),\\n        mask_fill_value=0, p=0.5),\\n        A.Normalize(img_color_mean, img_color_std), \\n        ToTensorV2()], p=1.),\\n     \\n    \"valid\": A.Compose([\\n        A.Resize(CONFIG[\\'img_size\\'], CONFIG[\\'img_size\\']),\\n        A.HorizontalFlip(p=0.5),\\n        A.VerticalFlip(p=0.5),\\n        A.Normalize(img_color_mean, img_color_std), \\n        ToTensorV2()], p=1.),\\n    \\n    \"test\": A.Compose([\\n        A.Resize(CONFIG[\\'img_size\\'], CONFIG[\\'img_size\\']),\\n        A.Normalize(img_color_mean, img_color_std), \\n        ToTensorV2()], p=1.),\\n    \\n    \\n\\n}\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_color_mean=[0.8661704276539922, 0.7663107094675368, 0.8574260897185548]\n",
    "img_color_std=[0.08670629753900036, 0.11646580094195522, 0.07164169171856792]\n",
    "\n",
    "\"\"\"\n",
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "        A.GaussNoise(var_limit=[10, 50]),\n",
    "        A.GaussianBlur(),\n",
    "        A.MotionBlur(),\n",
    "        ], p=0.4),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(512* 0.3), max_height=int(512* 0.3),\n",
    "        mask_fill_value=0, p=0.5),\n",
    "        A.Normalize(img_color_mean, img_color_std), \n",
    "        ToTensorV2()], p=1.),\n",
    "     \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Normalize(img_color_mean, img_color_std), \n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"test\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(img_color_mean, img_color_std), \n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \n",
    "\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d9dd6",
   "metadata": {
    "papermill": {
     "duration": 0.009544,
     "end_time": "2023-12-07T09:50:42.160982",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.151438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28d2f448",
   "metadata": {
    "papermill": {
     "duration": 0.009573,
     "end_time": "2023-12-07T09:50:42.180509",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.170936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2. Tiles Dataset\n",
    "\n",
    "### 2.2.1. Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be1b3885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.202384Z",
     "iopub.status.busy": "2023-12-07T09:50:42.201934Z",
     "iopub.status.idle": "2023-12-07T09:50:42.227898Z",
     "shell.execute_reply": "2023-12-07T09:50:42.226578Z"
    },
    "papermill": {
     "duration": 0.040545,
     "end_time": "2023-12-07T09:50:42.231070",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.190525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CancerTilesDataset(Dataset):\n",
    "    @staticmethod\n",
    "    def get_img_dir(data_row):\n",
    "        # based on if is_tma or not we select the respective image path\n",
    "        if data_row.is_tma == True:\n",
    "            return glob.glob(os.path.join(\"/kaggle/input/ubc-tma-tiles-512-05scale/UBC_TMA_tiles_1024p_scale05\", str(data_row.image_id), \"*.png\"))\n",
    "        else:\n",
    "            return glob.glob(os.path.join(\"/kaggle/input/tiles-of-cancer-2048px-scale-0-25\", str(data_row.image_id), \"*.png\")) \n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_data,\n",
    "        path_img_dir: str =  '',\n",
    "        transforms = None,\n",
    "        mode: str = 'train',\n",
    "        labels_lut = None,\n",
    "        white_thr: int = 225,\n",
    "        thr_max_bg: float = 0.2,\n",
    "        train_val_split: float = 0.90,\n",
    "        n_tiles: int = 1,\n",
    "        tma_weight: float = 1.0,\n",
    "    ):\n",
    "        assert os.path.isdir(path_img_dir)\n",
    "        self.path_img_dir = path_img_dir\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.white_thr = white_thr\n",
    "        self.thr_max_bg = thr_max_bg\n",
    "        self.train_val_split = train_val_split\n",
    "        self.n_tiles = n_tiles\n",
    "        self.tma_weight = tma_weight\n",
    "\n",
    "        self.data = df_data\n",
    "        self.labels_unique = sorted(self.data[\"label\"].unique())\n",
    "        self.labels_lut = labels_lut or {lb: i for i, lb in enumerate(self.labels_unique)}\n",
    "\n",
    "        self.data.is_tma = self.data.is_tma.astype(bool)\n",
    "        self.data = self.data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        # split dataset\n",
    "        assert 0.0 <= self.train_val_split <= 1.0\n",
    "        frac = int(self.train_val_split * len(self.data))\n",
    "        self.data = self.data[:frac] if mode in [\"train\", \"test\"] else self.data[frac:]\n",
    "        self.img_dirs = [CancerTilesDataset.get_img_dir(row) for i, row in self.data.iterrows()] \n",
    "        self.img_dirs = self.img_dirs * self.n_tiles\n",
    "        self.img_paths = []\n",
    "        #print(f\"missing: {sum([not os.path.isfile(os.path.join(self.path_img_dir, im))\n",
    "        #                       for im in self.img_names])}\")\n",
    "        # self.labels = list(self.data['label'])\n",
    "        self.labels =  np.array(self.data.target_label.values.tolist() * self.n_tiles)\n",
    "        \n",
    "        # set sample weights \n",
    "        self.sample_weights = [self.tma_weight if is_tma == True else 1 for is_tma in self.data[\"is_tma\"]] \n",
    "        self.sample_weights =  np.array(self.sample_weights * self.n_tiles)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        nth_iteration = idx//len(self.data)\n",
    "        if self.mode==\"train\":\n",
    "            random.seed()\n",
    "        else:\n",
    "            random.seed(CONFIG[\"seed\"]+nth_iteration)\n",
    "        random.shuffle(self.img_dirs[idx])\n",
    "        for img_path in self.img_dirs[idx]:\n",
    "            assert os.path.isfile(img_path), f\"missing: {img_path}\"\n",
    "            tile = cv2.imread(img_path)\n",
    "            tile = cv2.cvtColor(tile, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            # tile = np.array(Image.open(img_path))[..., :3]\n",
    "            black_bg = np.sum(tile, axis=2) == 0\n",
    "            tile[black_bg, :] = 255\n",
    "            mask_bg = np.mean(tile, axis=2) > self.white_thr\n",
    "            if np.sum(mask_bg) < (np.prod(mask_bg.shape) * self.thr_max_bg):\n",
    "                self.img_paths.append(img_path)\n",
    "                print(f\"Idx: {idx}, Path: {img_path}, len img_pths: {len(self.img_paths)}, nunique img_paths: {len(set(self.img_paths))}\")\n",
    "                break\n",
    "\n",
    "        # augmentation\n",
    "        if self.transforms:\n",
    "            tile = self.transforms(image=tile)[\"image\"]\n",
    "        #print(f\"img dim: {img.shape}\")\n",
    "        return {\n",
    "            \"image\": tile,\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "               }\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_dirs)\n",
    "    \n",
    "    def get_sample_weights(self):\n",
    "        return torch.from_numpy(self.sample_weights).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042eef7",
   "metadata": {
    "papermill": {
     "duration": 0.009783,
     "end_time": "2023-12-07T09:50:42.251434",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.241651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca85153b",
   "metadata": {
    "papermill": {
     "duration": 0.009795,
     "end_time": "2023-12-07T09:50:42.271490",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.261695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.2.2 Inference Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405ee02f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.293901Z",
     "iopub.status.busy": "2023-12-07T09:50:42.293478Z",
     "iopub.status.idle": "2023-12-07T09:50:42.321663Z",
     "shell.execute_reply": "2023-12-07T09:50:42.320407Z"
    },
    "papermill": {
     "duration": 0.042843,
     "end_time": "2023-12-07T09:50:42.324341",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.281498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_tiles(directory_path):\n",
    "    if os.path.isdir(directory_path):\n",
    "        for filename in os.listdir(directory_path):\n",
    "            if os.path.isfile(os.path.join(directory_path, filename)):\n",
    "                os.remove(os.path.join(directory_path, filename))\n",
    "\n",
    "def extract_image_tiles(\n",
    "    p_img, img_id, tmp_dir, size: int = 2048, scale: float = 0.5,\n",
    "    drop_thr: float = 0.8, white_thr: int = 245, max_samples: int = 50\n",
    ") -> list:\n",
    "    delete_tiles(tmp_dir)  # empty directory from previous images\n",
    "    im = pyvips.Image.new_from_file(p_img)\n",
    "    w = h = size\n",
    "    # https://stackoverflow.com/a/47581978/4521646\n",
    "    idxs = [(y, y + h, x, x + w) for y in range(0, im.height, h) for x in range(0, im.width, w)]\n",
    "    # random subsample\n",
    "    max_samples = max_samples if isinstance(max_samples, int) else int(len(idxs) * max_samples)\n",
    "    random.seed(42)\n",
    "    random.shuffle(idxs)\n",
    "    images = []\n",
    "    i = 0\n",
    "    for y, y_, x, x_ in (idxs):\n",
    "        i += 1\n",
    "        img_path = f\"{tmp_dir}/{str(i)}.png\"\n",
    "        # https://libvips.github.io/pyvips/vimage.html#pyvips.Image.crop\n",
    "        tile = im.crop(x, y, min(w, im.width - x), min(h, im.height - y)).numpy()[..., :3]\n",
    "        if tile.shape[:2] != (h, w):\n",
    "            tile_ = tile\n",
    "            tile_size = (h, w) if tile.ndim == 2 else (h, w, tile.shape[2])\n",
    "            tile = np.zeros(tile_size, dtype=tile.dtype)\n",
    "            tile[:tile_.shape[0], :tile_.shape[1], ...] = tile_\n",
    "        black_bg = np.sum(tile, axis=2) == 0\n",
    "        tile[black_bg, :] = 255\n",
    "        mask_bg = np.mean(tile, axis=2) > white_thr\n",
    "        if np.sum(mask_bg) >= (np.prod(mask_bg.shape) * drop_thr):\n",
    "            #print(f\"skip almost empty tile: {k:06}_{int(x_ / w)}-{int(y_ / h)}\")\n",
    "            continue\n",
    "        # print(tile.shape, tile.dtype, tile.min(), tile.max())\n",
    "        new_size = int(size * scale), int(size * scale)\n",
    "        tile = Image.fromarray(tile).resize(new_size, Image.LANCZOS)\n",
    "        tile.save(img_path)\n",
    "        images.append(img_path)\n",
    "        # need to set counter check as some empty tiles could be skipped earlier\n",
    "        if len(images) >= max_samples:\n",
    "            break\n",
    "    return images\n",
    "\n",
    "\n",
    "class TilesInferenceDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_path: str,\n",
    "        img_id: str = None,\n",
    "        tmp_dir: str = None,\n",
    "        size: int = 2048,\n",
    "        scale: float = 0.25,\n",
    "        white_thr: int = 225,\n",
    "        thr_max_bg: float = 0.6,\n",
    "        max_samples: int = 30,\n",
    "        transforms = None,\n",
    "        is_submission: bool = True,\n",
    "    ):\n",
    "        self.max_samples = max_samples\n",
    "        self.white_thr = white_thr\n",
    "        self.thr_max_bg = thr_max_bg\n",
    "        self.is_submission = is_submission\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        if self.is_submission:\n",
    "            # print(img_path)\n",
    "            assert os.path.isfile(img_path)\n",
    "            self.imgs = extract_image_tiles(\n",
    "                img_path, img_id, tmp_dir, size=size, scale=scale,\n",
    "                drop_thr=self.thr_max_bg, max_samples=max_samples)\n",
    "        else:  # test\n",
    "            all_imgs = glob.glob(os.path.join(img_path, img_id, \"*.png\"))\n",
    "            # Filter images based on background threshold\n",
    "            self.imgs = []\n",
    "            for img_path in all_imgs:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                black_bg = np.sum(img, axis=2) == 0\n",
    "                img[black_bg, :] = 255\n",
    "                mask_bg = np.mean(img, axis=2) > self.white_thr\n",
    "                if np.sum(mask_bg) <= (np.prod(mask_bg.shape) * self.thr_max_bg):\n",
    "                    self.imgs.append(img_path)  # Include this image\n",
    "            self.imgs = self.imgs[:self.max_samples]\n",
    "            # print(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        img = cv2.imread(self.imgs[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # filter background\n",
    "        mask = np.sum(img, axis=2) == 0\n",
    "        img[mask, :] = 255\n",
    "        if np.max(img) < 1.5:\n",
    "            img = np.clip(img * 255, 0, 255).astype(np.uint8)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "        return img\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd0a7e",
   "metadata": {
    "papermill": {
     "duration": 0.009984,
     "end_time": "2023-12-07T09:50:42.344711",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.334727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba6e600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.367058Z",
     "iopub.status.busy": "2023-12-07T09:50:42.366656Z",
     "iopub.status.idle": "2023-12-07T09:50:42.384044Z",
     "shell.execute_reply": "2023-12-07T09:50:42.382684Z"
    },
    "papermill": {
     "duration": 0.03235,
     "end_time": "2023-12-07T09:50:42.387278",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.354928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class UBCModel(nn.Module):\n",
    "    '''\n",
    "    EfficientNet B0 fine-tune.\n",
    "    '''\n",
    "    def __init__(self, model_name, num_classes, pretrained=False, checkpoint_path=None):\n",
    "        '''\n",
    "        Fine tune for EfficientNetB0\n",
    "        Args\n",
    "            n_classes : int - Number of classification categories.\n",
    "            learnable_modules : tuple - Names of the modules to fine-tune.\n",
    "        Return\n",
    "            \n",
    "        '''\n",
    "        super(UBCModel, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n",
    "\n",
    "        in_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.pooling = GeM()\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward function for the fine-tuned model\n",
    "        Args\n",
    "            x: \n",
    "        Return\n",
    "            result\n",
    "        \"\"\"\n",
    "        features = self.model(images)\n",
    "        pooled_features = self.pooling(features).flatten(1)\n",
    "        output = self.linear(pooled_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9733ff16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.410949Z",
     "iopub.status.busy": "2023-12-07T09:50:42.409869Z",
     "iopub.status.idle": "2023-12-07T09:50:42.420768Z",
     "shell.execute_reply": "2023-12-07T09:50:42.419777Z"
    },
    "papermill": {
     "duration": 0.025712,
     "end_time": "2023-12-07T09:50:42.423407",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.397695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47da9e",
   "metadata": {
    "papermill": {
     "duration": 0.009485,
     "end_time": "2023-12-07T09:50:42.442816",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.433331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3681ea4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.465734Z",
     "iopub.status.busy": "2023-12-07T09:50:42.465246Z",
     "iopub.status.idle": "2023-12-07T09:50:42.484594Z",
     "shell.execute_reply": "2023-12-07T09:50:42.483258Z"
    },
    "papermill": {
     "duration": 0.034172,
     "end_time": "2023-12-07T09:50:42.487582",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.453410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fetch_scheduler(optimizer, CONFIG):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'], verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        CONFIG['T_0'] = 10\n",
    "        CONFIG['T_mult'] = 2\n",
    "        CONFIG['min_lr'] = 1e-6\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG['T_0'], T_mult=CONFIG['T_mult'],\n",
    "                                                             eta_min=CONFIG['min_lr'], verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'ReduceLROnPlateau':\n",
    "        scheduler =  ReduceLROnPlateau(optimizer, mode='min', factor=kwargs.get('factor', 0.1), patience=kwargs.get('patience', 5), verbose=False)\n",
    "    elif CONFIG['scheduler'] == 'LambdaLR':\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "    return scheduler\n",
    "\n",
    "def get_optimizer(optimizer_name, model):\n",
    "    if optimizer_name.lower() == \"adam\":\n",
    "        CONFIG['learning_rate'] = 1e-4\n",
    "        CONFIG['weight_decay'] = 1e-5\n",
    "        CONFIG['betas'] = (0.9, 0.999)\n",
    "        CONFIG['eps'] = 1e-8\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], betas=CONFIG['betas'], eps=CONFIG['eps'],  weight_decay=CONFIG['weight_decay'])\n",
    "    elif optimizer_name.lower() == \"sgd\":\n",
    "        CONFIG['learning_rate'] = 1e-3\n",
    "        CONFIG['weight_decay'] = 1e-3\n",
    "        CONFIG['momentum'] = 1e-3\n",
    "        optimizer = optim.SGD(model.parameters(), lr=CONFIG['learning_rate'], momentum=CONFIG['momentum'], weight_decay=CONFIG['weight_decay'])\n",
    "    elif optimizer_name.lower() == \"radam\":\n",
    "        CONFIG['learning_rate'] = 1e-4\n",
    "        CONFIG['weight_decay'] = 0\n",
    "        CONFIG['betas'] = (0.9, 0.999)\n",
    "        CONFIG['eps'] = 1e-8\n",
    "        optimizer = torch_optimizer.RAdam(\n",
    "            model.parameters(),\n",
    "            lr= CONFIG['learning_rate'],\n",
    "            betas=CONFIG['betas'],\n",
    "            eps=CONFIG['eps'],\n",
    "            weight_decay=CONFIG['weight_decay'],\n",
    "        )\n",
    "    elif optimizer_name.lower() == \"rmsprop\":\n",
    "        CONFIG['learning_rate'] = 0.256\n",
    "        CONFIG['alpha'] = 0.9\n",
    "        CONFIG['momentum'] = 0.9\n",
    "        CONFIG['weight_decay'] = 1e-5\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=CONFIG['learning_rate'], alpha=CONFIG['learning_rate'], \n",
    "                                  momentum=CONFIG['learning_rate'], weight_decay=CONFIG['learning_rate'])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Optimizer given!\")\n",
    "    return optimizer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72acdc55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.509795Z",
     "iopub.status.busy": "2023-12-07T09:50:42.509290Z",
     "iopub.status.idle": "2023-12-07T09:50:42.529255Z",
     "shell.execute_reply": "2023-12-07T09:50:42.527644Z"
    },
    "papermill": {
     "duration": 0.034922,
     "end_time": "2023-12-07T09:50:42.532215",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.497293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_dict_to_tensor(dict_):\n",
    "    \"\"\"Converts the values of a dict into a PyTorch tensor.\"\"\"\n",
    "\n",
    "    # Create a new PyTorch tensor\n",
    "    tensor = torch.empty(len(dict_))\n",
    "\n",
    "    # Iterate over the dict and for each key-value pair, convert the value to a PyTorch tensor and add it to the new tensor\n",
    "    for i, (key, value) in enumerate(dict_.items()):\n",
    "        tensor[i] = value\n",
    "\n",
    "    # Return the new tensor\n",
    "    return tensor\n",
    "\n",
    "def get_class_weights(df_train):\n",
    "    label_counts = df_train.target_label.value_counts().sort_index().to_dict()\n",
    "    ratios_dict = {}\n",
    "    for key,val in label_counts.items():\n",
    "        ratios_dict[key] = val / df_train.shape[0]\n",
    "    ratios_dict\n",
    "    weights = {}\n",
    "    sum_weights = 0\n",
    "    for key, val in ratios_dict.items():\n",
    "        weights[key] = 1 / val\n",
    "        sum_weights +=  1 / val\n",
    "    for key, val in weights.items():\n",
    "        weights[key] = val / sum_weights\n",
    "    weight_tensor = convert_dict_to_tensor(weights)\n",
    "    return weight_tensor\n",
    "\n",
    "def get_dataloaders(df, TRAIN_DIR, CONFIG, data_transforms, n_tiles=1, train_val_split=0.9, apply_sampler=True, tma_weight=1, sample_fac=1):\n",
    "    # df_train = df[df[\"kfold\"]!=fold].reset_index(drop=True)\n",
    "    train_dataset = CancerTilesDataset(df, TRAIN_DIR, transforms=data_transforms[\"train\"], mode=\"train\", n_tiles=n_tiles, train_val_split=train_val_split, tma_weight=tma_weight)\n",
    "    if apply_sampler:\n",
    "        samples_weights = train_dataset.get_sample_weights()\n",
    "        train_sampler = WeightedRandomSampler(samples_weights, len(samples_weights)*sample_fac)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], num_workers=2, sampler=train_sampler, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    valid_dataset = CancerTilesDataset(df, TRAIN_DIR, transforms=data_transforms[\"valid\"], mode=\"valid\", n_tiles=n_tiles, train_val_split=train_val_split, tma_weight=tma_weight)\n",
    "    if apply_sampler:\n",
    "        samples_weights = valid_dataset.get_sample_weights()\n",
    "        valid_sampler = WeightedRandomSampler(samples_weights, len(samples_weights)*sample_fac)\n",
    "    else:\n",
    "        valid_sampler=None\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], num_workers=2, sampler=valid_sampler, shuffle=False, pin_memory=True)\n",
    "    print(f\"Len Train Dataset: {len(train_dataset)}, Len Validation Dataset: {len(valid_dataset)}\" )\n",
    "    return train_loader, valid_loader, df\n",
    "\n",
    "def print_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(f\"run_id: {r.info.run_id}\")\n",
    "    print(f\"artifacts: {artifacts}\")\n",
    "    print(f\"params: {r.data.params}\")\n",
    "    print(f\"metrics: {r.data.metrics}\")\n",
    "    print(f\"tags: {tags}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021f979",
   "metadata": {
    "papermill": {
     "duration": 0.009624,
     "end_time": "2023-12-07T09:50:42.552413",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.542789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2362f34",
   "metadata": {
    "papermill": {
     "duration": 0.010083,
     "end_time": "2023-12-07T09:50:42.572767",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.562684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Inference & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff2a7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.595255Z",
     "iopub.status.busy": "2023-12-07T09:50:42.594789Z",
     "iopub.status.idle": "2023-12-07T09:50:42.607830Z",
     "shell.execute_reply": "2023-12-07T09:50:42.606547Z"
    },
    "papermill": {
     "duration": 0.027297,
     "end_time": "2023-12-07T09:50:42.610387",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.583090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_predictions(df):\n",
    "    # Total Accuracy\n",
    "    total_accuracy = accuracy_score(df['target_label'], df['label'])\n",
    "\n",
    "    # Balanced Accuracy\n",
    "    balanced_accuracy = balanced_accuracy_score(df['target_label'], df['label'])\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(df['target_label'], df['label'], average='weighted')\n",
    "\n",
    "    # Accuracy Per Class\n",
    "    cm = confusion_matrix(df['target_label'], df['label'])\n",
    "    class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    print(f\"Total Accuracy: {total_accuracy}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Accuracy Per Class: {class_accuracy}\")\n",
    "    display(cm)\n",
    "    \n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "def score_predictions(preds, method=\"sum\", N=10):\n",
    "    if method==\"sum\":  # sum up the predictions of all tiles/models\n",
    "        lb = np.argmax(np.sum(preds, axis=0))\n",
    "    elif method in [\"most_frequent\", \"most_votes\", \"majority_vote\"]:  # get majority vote over all tiles/models \n",
    "        lb = most_frequent(np.argmax(preds, axis=1).tolist())\n",
    "    elif method == \"n_highest_sum\":  # sum up predictions of N-most decicive tiles/models\n",
    "        max_vals = np.max(preds, axis=1).tolist()\n",
    "        max_idxs = [max_vals.index(i) for i in heapq.nlargest(N, max_vals)]\n",
    "        n_tiles_preds = np.take(preds, max_idxs, axis=0).tolist()\n",
    "        lb = np.argmax(np.sum(n_tiles_preds, axis=0))\n",
    "    else:\n",
    "        print(\"No method found: Apply Sum Method for Scoring predictions!\")\n",
    "        lb = np.argmax(np.sum(preds, axis=0))\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b2e56aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T09:50:42.632327Z",
     "iopub.status.busy": "2023-12-07T09:50:42.631850Z",
     "iopub.status.idle": "2023-12-07T09:50:42.647447Z",
     "shell.execute_reply": "2023-12-07T09:50:42.646536Z"
    },
    "papermill": {
     "duration": 0.029743,
     "end_time": "2023-12-07T09:50:42.649975",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.620232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_single_image_ensemble(idx_row, models, CONFIG, score_method=\"sum\", max_samples=30, is_submission=True, device=\"cuda\") -> dict:\n",
    "    \"\"\"\n",
    "    Create tiled-dataset based on test image.\n",
    "    Iterate throuh all tiles and apply model prediction.\n",
    "    Select highest of sum of all logits.\n",
    "    \"\"\"\n",
    "    row = dict(idx_row[1])\n",
    "    img_id = str(row[\"image_id\"])\n",
    "    result = {\"image_id\": img_id}\n",
    "    if is_submission:\n",
    "        print(\"Image ID: \", img_id)\n",
    "        result[\"target_label\"] = row[\"target_label\"]\n",
    "        # prepare data - cut and load tiles\n",
    "        dataset = TilesInferenceDataset(\n",
    "            os.path.join(\"/kaggle/input/UBC-OCEAN/\", \"train_images\", f\"{img_id}.png\"),\n",
    "            size=2048, scale=0.25, transforms=data_transforms[\"valid\"], max_samples=max_samples)\n",
    "    else:\n",
    "        print(\"Image ID: \", img_id)\n",
    "        dataset = TilesInferenceDataset(\n",
    "            \"/kaggle/input/tiles-of-cancer-2048px-scale-0-25\",\n",
    "            img_id,\n",
    "            size=2048, scale=0.25, transforms=data_transforms[\"valid\"], is_submission=is_submission, max_samples=max_samples)\n",
    "        result[\"target_label\"] = row[\"target_label\"]\n",
    "        \n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=CONFIG[\"valid_batch_size\"], num_workers=1, shuffle=False,\n",
    "        # see: https://github.com/pytorch/pytorch/issues/44687#issuecomment-790842173\n",
    "        multiprocessing_context=get_context('loky')\n",
    "    )\n",
    "    if not len(dataset):\n",
    "        if not is_submission: \n",
    "            print (f\"seem no tiles were cut for `{row['image_id']}`. Set to label 0\")\n",
    "            print (row)\n",
    "        result[\"label\"] = 0\n",
    "        return result\n",
    "    \n",
    "    if not isinstance(models, list):\n",
    "        models = [models]\n",
    "    \n",
    "    model_preds_sum = []\n",
    "    for i,model in enumerate(models):\n",
    "        #print(f\"Apply Model {i+1} of {len(models)}\")\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        # iterate over images and collect predictions | \n",
    "        for imgs in dataloader:\n",
    "            # print(f\"{imgs.shape}\")\n",
    "            with torch.no_grad():\n",
    "                pred = model(imgs.to(device))\n",
    "            preds += pred.cpu().numpy().tolist()\n",
    "        if not is_submission:\n",
    "            print(f\"Sum contrinution from all tiles: {np.sum(preds, axis=0)}\")\n",
    "            print(f\"Max contribution over all tiles: {np.max(preds, axis=0)}\")\n",
    "        model_preds_sum.append(preds)\n",
    "    model_preds_sum = sum(model_preds_sum, [])\n",
    "    # decide label\n",
    "    prediction = score_predictions(model_preds_sum, method=score_method)\n",
    "    result[\"label\"] = prediction\n",
    "    if not is_submission: \n",
    "        result[\"target_label\"] = row[\"target_label\"]\n",
    "    result[\"predictions\"] = np.sum(model_preds_sum, axis=0).tolist()\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45333d",
   "metadata": {
    "papermill": {
     "duration": 0.009911,
     "end_time": "2023-12-07T09:50:42.670447",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.660536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7f51f",
   "metadata": {
    "papermill": {
     "duration": 0.009886,
     "end_time": "2023-12-07T09:50:42.690561",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.680675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff96bd5",
   "metadata": {
    "papermill": {
     "duration": 0.009844,
     "end_time": "2023-12-07T09:50:42.710746",
     "exception": false,
     "start_time": "2023-12-07T09:50:42.700902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6924515,
     "sourceId": 45867,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.696354,
   "end_time": "2023-12-07T09:50:45.466274",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-07T09:50:26.769920",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
