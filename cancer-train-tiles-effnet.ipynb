{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":6755371,"sourceType":"datasetVersion","datasetId":3888697},{"sourceId":6917177,"sourceType":"datasetVersion","datasetId":3889865},{"sourceId":7018060,"sourceType":"datasetVersion","datasetId":4035314},{"sourceId":7034655,"sourceType":"datasetVersion","datasetId":4046783},{"sourceId":6984590,"sourceType":"datasetVersion","datasetId":4014175}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction \n\n**This is a basic CNN Model training notebook**\n\nIt is based on: \n- Thumbnail images\n- Basic data transformation (using Albumentation):\n    - resizing images to 512x512\n    - normalizing pixel values\n- CNN Architecture\n\n\n**Todos:**\n\n- Learn about Dataset & DataLoader\n- add augmentations (albumentation)\n- gem pooling","metadata":{}},{"cell_type":"code","source":"!pip install --quiet torch_optimizer","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:04.374173Z","iopub.execute_input":"2023-11-24T19:57:04.374413Z","iopub.status.idle":"2023-11-24T19:57:17.662866Z","shell.execute_reply.started":"2023-11-24T19:57:04.374391Z","shell.execute_reply":"2023-11-24T19:57:17.661603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet mlflow dagshub","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:17.665064Z","iopub.execute_input":"2023-11-24T19:57:17.665346Z","iopub.status.idle":"2023-11-24T19:57:36.600262Z","shell.execute_reply.started":"2023-11-24T19:57:17.665322Z","shell.execute_reply":"2023-11-24T19:57:36.599196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport os\nimport gc\nimport cv2\nimport datetime\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\nfrom skimage import io\n\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.cuda import amp\nimport torchvision\nimport torch_optimizer as torch_optimizer\n\nimport optuna\nfrom optuna.trial import TrialState\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nfrom tqdm.auto import tqdm\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score\n\n# For Image Models\nimport timm\n\nimport dagshub\nfrom getpass import getpass\nimport mlflow.pytorch \nfrom mlflow import MlflowClient\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\n# warnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:36.601687Z","iopub.execute_input":"2023-11-24T19:57:36.602099Z","iopub.status.idle":"2023-11-24T19:57:51.182576Z","shell.execute_reply.started":"2023-11-24T19:57:36.602062Z","shell.execute_reply":"2023-11-24T19:57:51.181819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"Niggl0n\"\nos.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"7a3590e8c5558d4598dacc7810befa70a4baac9e\"\nos.environ['MLFLOW_TRACKING_PROJECTNAME'] = \"UBC_Cancer_Classification\"\n#dagshub.auth.add_app_token(\"7a3590e8c5558d4598dacc7810befa70a4baac9e\")\nmlflow.set_tracking_uri(f'https://dagshub.com/' + os.environ['MLFLOW_TRACKING_USERNAME'] + '/' + os.environ['MLFLOW_TRACKING_PROJECTNAME'] + '.mlflow')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.184881Z","iopub.execute_input":"2023-11-24T19:57:51.185439Z","iopub.status.idle":"2023-11-24T19:57:51.190557Z","shell.execute_reply.started":"2023-11-24T19:57:51.185410Z","shell.execute_reply":"2023-11-24T19:57:51.189591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_or_create_experiment_id(name):\n    exp = mlflow.get_experiment_by_name(name)\n    if exp is None:\n        exp_id = mlflow.create_experiment(name)\n        return exp_id\n    return exp.experiment_id\n\nmlflow_experiment_id = get_or_create_experiment_id(os.environ['MLFLOW_TRACKING_PROJECTNAME'])\nmlflow_experiment_id","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.191961Z","iopub.execute_input":"2023-11-24T19:57:51.192373Z","iopub.status.idle":"2023-11-24T19:57:51.505683Z","shell.execute_reply.started":"2023-11-24T19:57:51.192324Z","shell.execute_reply":"2023-11-24T19:57:51.504781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    \"is_submission\": False,\n    \"weighted_loss\": True,\n    \"datetime_now\": datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"), \n    \"n_fold\":5, \n    \"test_fold\": 0,\n    \"seed\": 42,\n    \"img_size\": 512,\n    \"model_name\": \"tf_efficientnetv2_s_in21ft1k\",   # \"tf_efficientnet_b0_ns\", # \"tf_efficientnetv2_s_in21ft1k\"\n    \"checkpoint_path\": \"/kaggle/input/tf-efficientnet-b0-aa-827b6e33-pth/tf_efficientnet_b0_aa-827b6e33.pth\",\n    \"num_classes\": 5,\n    \"train_batch_size\": 8,\n    \"valid_batch_size\": 8,\n    \"n_tiles\": 10,\n    \"n_tiles_test\": 10,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    \"num_epochs\": 15,\n    \"early_stopping\": True,\n    \"patience\": 6,\n    \"optimizer\": 'adam',\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 10,\n    \"momentum\": 0.9,\n    \"weight_decay\": 1e-4,\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:58:10.781528Z","iopub.execute_input":"2023-11-24T19:58:10.782368Z","iopub.status.idle":"2023-11-24T19:58:10.790356Z","shell.execute_reply.started":"2023-11-24T19:58:10.782323Z","shell.execute_reply":"2023-11-24T19:58:10.789496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Data Preparation","metadata":{}},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input/UBC-OCEAN'\nTRAIN_DIR = '/kaggle/input/tiles-of-cancer-2048px-scale-0-25/'\nTEST_DIR = '/kaggle/input/UBC-OCEAN/test_thumbnails'\n\n# ALT_TEST_DIR = '/kaggle/input/UBC-OCEAN/test_images'\n# TMA_TRAIN_DIR = '/kaggle/input/UBC-OCEAN/train_images'\n\ndef get_train_file_path(df_train_row):\n    return f\"{TRAIN_DIR}{df_train_row.image_id}.png\"\n\ndef get_test_file_path(image_id):\n    if os.path.exists(f\"{TEST_DIR}/{image_id}_thumbnail.png\"):\n        return f\"{TEST_DIR}/{image_id}_thumbnail.png\"\n    else:\n        return f\"{ALT_TEST_DIR}/{image_id}.png\"\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.546941Z","iopub.execute_input":"2023-11-24T19:57:51.547556Z","iopub.status.idle":"2023-11-24T19:57:51.556754Z","shell.execute_reply.started":"2023-11-24T19:57:51.547519Z","shell.execute_reply":"2023-11-24T19:57:51.556000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.png\"))\ndf_train = pd.read_csv(\"/kaggle/input/UBC-OCEAN/train.csv\")\nprint(df_train.shape)\ndf_train['file_path'] = df_train.apply(lambda row: get_train_file_path(row), axis=1)\n# only consider WSI / Thumbnail images\n#df_train = df_train[ \n#    df_train[\"file_path\"].isin(train_images) ].reset_index(drop=True)\nprint(df_train.shape)\n\n# encode to numericalt target\nencoder = LabelEncoder()\ndf_train['target_label'] = encoder.fit_transform(df_train['label'])\n\n# save encoder\nwith open(\"label_encoder_\"+ CONFIG[\"datetime_now\"] +\".pkl\", \"wb\") as fp:\n    joblib.dump(encoder, fp)\n    \n# use stratified K Fold for crossvalidation \nskf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG[\"seed\"])\n\nfor fold, ( _, val_) in enumerate(skf.split(X=df_train, y=df_train.target_label)):\n    df_train.loc[val_ , \"kfold\"] = int(fold)\ndisplay(df_train.head())\n\n# separate train and test dataset\ndf_test = df_train[df_train[\"kfold\"]==CONFIG[\"test_fold\"]].reset_index(drop=True)\ndf_train = df_train[df_train[\"kfold\"]!=CONFIG[\"test_fold\"]].reset_index(drop=True)\nprint(f\"Shape df_train: {df_train.shape}, Shape df_test: {df_test.shape} \")","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.557993Z","iopub.execute_input":"2023-11-24T19:57:51.558333Z","iopub.status.idle":"2023-11-24T19:57:51.654254Z","shell.execute_reply.started":"2023-11-24T19:57:51.558301Z","shell.execute_reply":"2023-11-24T19:57:51.653444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.loc[0, \"file_path\"]","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.655186Z","iopub.execute_input":"2023-11-24T19:57:51.655445Z","iopub.status.idle":"2023-11-24T19:57:51.661747Z","shell.execute_reply.started":"2023-11-24T19:57:51.655421Z","shell.execute_reply":"2023-11-24T19:57:51.660811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndef _color_means(img_path):\n    img = np.array(Image.open(img_path))\n    mask = np.sum(img[..., :3], axis=2) == 0\n    img[mask, :] = 255\n    if np.max(img) > 1.5:\n        img = img / 255.0\n    clr_mean = {i: np.mean(img[..., i]) for i in range(3)}\n    clr_std = {i: np.std(img[..., i]) for i in range(3)}\n    return clr_mean, clr_std\n\n# os.path.join(DATASET_SMALL_FOLDER, \"train_images\")\nls_images = glob.glob(os.path.join(TRAIN_DIR, \"*\", \"*.png\"))\nclr_mean_std = Parallel(n_jobs=os.cpu_count())(delayed(_color_means)(fn) for fn in tqdm(ls_images[:9000]))\n\nimg_color_mean = pd.DataFrame([c[0] for c in clr_mean_std]).describe()\ndisplay(img_color_mean.T)\nimg_color_std = pd.DataFrame([c[1] for c in clr_mean_std]).describe()\ndisplay(img_color_std.T)\n\nimg_color_mean = list(img_color_mean.T[\"mean\"])\nimg_color_std = list(img_color_std.T[\"mean\"])\nprint(f\"{img_color_mean=}\\n{img_color_std=}\")\n\"\"\"\n\n## histogram matching \n#from skimage.exposure import match_histograms\n#ref_img = np.array(Image.open(\"/kaggle/input/tiles-of-cancer-2048px-scale-0-25/10077/000067_16-3.png\"))\n#bef_img = np.array(Image.open(\"/kaggle/input/tiles-of-cancer-2048px-scale-0-25/12522/000028_6-2.png\"))\n#start = time.time()\n#aft_img = match_histograms(bef_img, ref_img, channel_axis=-1)\n#print(time.time()-start)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.665519Z","iopub.execute_input":"2023-11-24T19:57:51.665881Z","iopub.status.idle":"2023-11-24T19:57:51.673300Z","shell.execute_reply.started":"2023-11-24T19:57:51.665849Z","shell.execute_reply":"2023-11-24T19:57:51.672420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CancerTilesDataset(Dataset):\n    def __init__(\n        self,\n        df_data,\n        path_img_dir: str =  '',\n        transforms = None,\n        mode: str = 'train',\n        labels_lut = None,\n        white_thr: int = 225,\n        thr_max_bg: float = 0.2,\n        split: float = 0.90,\n        n_tiles: int = 1\n    ):\n        assert os.path.isdir(path_img_dir)\n        self.path_img_dir = path_img_dir\n        self.transforms = transforms\n        self.mode = mode\n        self.white_thr = white_thr\n        self.thr_max_bg = thr_max_bg\n        self.split = split\n        self.n_tiles = n_tiles\n\n        self.data = df_data\n        self.labels_unique = sorted(self.data[\"label\"].unique())\n        self.labels_lut = labels_lut or {lb: i for i, lb in enumerate(self.labels_unique)}\n        # shuffle data\n        self.data = self.data.sample(frac=1, random_state=42).reset_index(drop=True)\n\n        # split dataset\n        assert 0.0 <= self.split <= 1.0\n        frac = int(self.split * len(self.data))\n        self.data = self.data[:frac] if mode in [\"train\", \"test\"] else self.data[frac:]\n        self.img_dirs = [glob.glob(os.path.join(path_img_dir, str(idx), \"*.png\")) for idx in self.data[\"image_id\"]] \n        self.img_dirs = self.img_dirs * self.n_tiles\n        self.img_paths = []\n        #print(f\"missing: {sum([not os.path.isfile(os.path.join(self.path_img_dir, im))\n        #                       for im in self.img_names])}\")\n        # self.labels = list(self.data['label'])\n        self.labels =  np.array(self.data.target_label.values.tolist() * self.n_tiles)\n\n    def __getitem__(self, idx: int) -> tuple:\n        nth_iteration = idx//len(self.data)\n        if self.mode==\"train\":\n            random.seed()\n        else:\n            random.seed(CONFIG[\"seed\"]+nth_iteration)\n        random.shuffle(self.img_dirs[idx])\n        for img_path in self.img_dirs[idx]:\n            assert os.path.isfile(img_path), f\"missing: {img_path}\"\n            tile = cv2.imread(img_path)\n            tile = cv2.cvtColor(tile, cv2.COLOR_BGR2RGB)\n        \n            # tile = np.array(Image.open(img_path))[..., :3]\n            black_bg = np.sum(tile, axis=2) == 0\n            tile[black_bg, :] = 255\n            mask_bg = np.mean(tile, axis=2) > self.white_thr\n            if np.sum(mask_bg) < (np.prod(mask_bg.shape) * self.thr_max_bg):\n                #self.img_paths.append(img_path)\n                #print(f\"Idx: {idx}, Path: {img_path}, len img_pths: {len(self.img_paths)}, nunique img_paths: {len(set(self.img_paths))}\")\n                break\n\n        if self.transforms:\n            tile = self.transforms(image=tile)[\"image\"]\n        #print(f\"img dim: {img.shape}\")\n        return {\n            \"image\": tile,\n            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n               }\n    def __len__(self) -> int:\n        return len(self.img_dirs)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.674513Z","iopub.execute_input":"2023-11-24T19:57:51.674900Z","iopub.status.idle":"2023-11-24T19:57:51.691945Z","shell.execute_reply.started":"2023-11-24T19:57:51.674867Z","shell.execute_reply":"2023-11-24T19:57:51.691135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_color_mean=[0.8661704276539922, 0.7663107094675368, 0.8574260897185548]\nimg_color_std=[0.08670629753900036, 0.11646580094195522, 0.07164169171856792]\n\ndata_transforms = {\n    \"train\": A.Compose([\n        A.Resize(512, 512),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomBrightnessContrast(p=0.75),\n        A.ShiftScaleRotate(p=0.75),\n        A.OneOf([\n        A.GaussNoise(var_limit=[10, 50]),\n        A.GaussianBlur(),\n        A.MotionBlur(),\n        ], p=0.4),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n        A.CoarseDropout(max_holes=1, max_width=int(512* 0.3), max_height=int(512* 0.3),\n        mask_fill_value=0, p=0.5),\n        A.Normalize(img_color_mean, img_color_std), \n        ToTensorV2()], p=1.),\n    \n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(img_color_mean, img_color_std), \n        ToTensorV2()], p=1.)\n}\n\n\"\"\"        A.Normalize(\n            mean=[0.485, 0.456, 0.406], \n            std=[0.229, 0.224, 0.225], \n            max_pixel_value=255.0, \n            p=1.0\n        ),\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.693001Z","iopub.execute_input":"2023-11-24T19:57:51.693270Z","iopub.status.idle":"2023-11-24T19:57:51.709164Z","shell.execute_reply.started":"2023-11-24T19:57:51.693247Z","shell.execute_reply":"2023-11-24T19:57:51.708301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Model Creation","metadata":{}},{"cell_type":"code","source":"class GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = nn.Parameter(torch.ones(1)*p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n        \n    def __repr__(self):\n        return self.__class__.__name__ + \\\n                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n                ', ' + 'eps=' + str(self.eps) + ')'\n\n\nclass UBCModel(nn.Module):\n\n    def __init__(self, model_name, num_classes, pretrained=False, checkpoint_path=None):\n        '''\n        Fine tune for EfficientNetB0\n        Args\n            n_classes : int - Number of classification categories.\n            learnable_modules : tuple - Names of the modules to fine-tune.\n        Return\n            \n        '''\n        super(UBCModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n\n        in_features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.model.global_pool = nn.Identity()\n        self.pooling = GeM()\n        self.linear = nn.Linear(in_features, num_classes)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, images):\n        \"\"\"\n        Forward function for the fine-tuned model\n        Args\n            x: \n        Return\n            result\n        \"\"\"\n        features = self.model(images)\n        pooled_features = self.pooling(features).flatten(1)\n        output = self.linear(pooled_features)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.710188Z","iopub.execute_input":"2023-11-24T19:57:51.710466Z","iopub.status.idle":"2023-11-24T19:57:51.722969Z","shell.execute_reply.started":"2023-11-24T19:57:51.710435Z","shell.execute_reply":"2023-11-24T19:57:51.722180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Training","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = float('inf')\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''Saves model when validation loss decreases.'''\n        if self.verbose:\n            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model to path {self.path}')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.724218Z","iopub.execute_input":"2023-11-24T19:57:51.724537Z","iopub.status.idle":"2023-11-24T19:57:51.737940Z","shell.execute_reply.started":"2023-11-24T19:57:51.724506Z","shell.execute_reply":"2023-11-24T19:57:51.737094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'], verbose=False)\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        CONFIG['T_0'] = 20\n        CONFIG['T_mult'] = 2\n        CONFIG['min_lr'] = 1e-6\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG['T_0'], T_mult=CONFIG['T_mult'],\n                                                             eta_min=CONFIG['min_lr'], verbose=False)\n    elif CONFIG['scheduler'] == 'ReduceLROnPlateau':\n        scheduler =  ReduceLROnPlateau(optimizer, mode='min', factor=kwargs.get('factor', 0.1), patience=kwargs.get('patience', 5), verbose=False)\n    elif CONFIG['scheduler'] == 'LambdaLR':\n        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler\n\ndef get_optimizer(optimizer_name, model):\n    if optimizer_name.lower() == \"adam\":\n        CONFIG['learning_rate'] = 1e-4\n        CONFIG['weight_decay'] = 1e-5\n        CONFIG['betas'] = (0.9, 0.999)\n        CONFIG['eps'] = 1e-8\n        optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], betas=CONFIG['betas'], eps=CONFIG['eps'],  weight_decay=CONFIG['weight_decay'])\n    elif optimizer_name.lower() == \"sgd\":\n        CONFIG['learning_rate'] = 1e-3\n        CONFIG['weight_decay'] = 1e-3\n        CONFIG['momentum'] = 1e-3\n        optimizer = optim.SGD(model.parameters(), lr=CONFIG['learning_rate'], momentum=CONFIG['momentum'], weight_decay=CONFIG['weight_decay'])\n    elif optimizer_name.lower() == \"radam\":\n        CONFIG['learning_rate'] = 1e-4\n        CONFIG['weight_decay'] = 0\n        CONFIG['betas'] = (0.9, 0.999)\n        CONFIG['eps'] = 1e-8\n        optimizer = torch_optimizer.RAdam(\n            model.parameters(),\n            lr= CONFIG['learning_rate'],\n            betas=CONFIG['betas'],\n            eps=CONFIG['eps'],\n            weight_decay=CONFIG['weight_decay'],\n        )\n    elif optimizer_name.lower() == \"rmsprop\":\n        CONFIG['learning_rate'] = 0.256\n        CONFIG['alpha'] = 0.9\n        CONFIG['momentum'] = 0.9\n        CONFIG['weight_decay'] = 1e-5\n        optimizer = optim.RMSprop(model.parameters(), lr=CONFIG['learning_rate'], alpha=CONFIG['learning_rate'], \n                                  momentum=CONFIG['learning_rate'], weight_decay=CONFIG['learning_rate'])\n    else:\n        raise ValueError(\"Invalid Optimizer given!\")\n    return optimizer\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.738884Z","iopub.execute_input":"2023-11-24T19:57:51.739209Z","iopub.status.idle":"2023-11-24T19:57:51.754150Z","shell.execute_reply.started":"2023-11-24T19:57:51.739177Z","shell.execute_reply":"2023-11-24T19:57:51.753444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_dict_to_tensor(dict_):\n    \"\"\"Converts the values of a dict into a PyTorch tensor.\"\"\"\n\n    # Create a new PyTorch tensor\n    tensor = torch.empty(len(dict_))\n\n    # Iterate over the dict and for each key-value pair, convert the value to a PyTorch tensor and add it to the new tensor\n    for i, (key, value) in enumerate(dict_.items()):\n        tensor[i] = value\n\n    # Return the new tensor\n    return tensor\n\ndef get_class_weights(df_train):\n    label_counts = df_train.target_label.value_counts().sort_index().to_dict()\n    ratios_dict = {}\n    for key,val in label_counts.items():\n        ratios_dict[key] = val / df_train.shape[0]\n    ratios_dict\n    weights = {}\n    sum_weights = 0\n    for key, val in ratios_dict.items():\n        weights[key] = 1 / val\n        sum_weights +=  1 / val\n    for key, val in weights.items():\n        weights[key] = val / sum_weights\n    weight_tensor = convert_dict_to_tensor(weights)\n    return weight_tensor\n\ndef get_dataloaders(df, n_tiles=1):\n    # df_train = df[df[\"kfold\"]!=fold].reset_index(drop=True)\n    train_dataset = CancerTilesDataset(df_train, TRAIN_DIR, transforms=data_transforms[\"train\"], mode=\"train\", n_tiles=n_tiles)\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=2, shuffle=False, pin_memory=True)\n    valid_dataset = CancerTilesDataset(df_train, TRAIN_DIR, transforms=data_transforms[\"valid\"], mode=\"valid\", n_tiles=n_tiles)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=2, shuffle=False, pin_memory=True)\n    print(f\"Len Train Dataset: {len(train_dataset)}, Len Validation Dataset: {len(valid_dataset)}\" )\n    return train_loader, valid_loader, df_train\n\ndef print_logged_info(r):\n    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n    print(f\"run_id: {r.info.run_id}\")\n    print(f\"artifacts: {artifacts}\")\n    print(f\"params: {r.data.params}\")\n    print(f\"metrics: {r.data.metrics}\")\n    print(f\"tags: {tags}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.755435Z","iopub.execute_input":"2023-11-24T19:57:51.756130Z","iopub.status.idle":"2023-11-24T19:57:51.769419Z","shell.execute_reply.started":"2023-11-24T19:57:51.756098Z","shell.execute_reply":"2023-11-24T19:57:51.768470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, train_loader, optimizer, criterion, device, writer, epoch, scheduler=None):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    model.train()\n    train_loss = 0.0\n    bar = tqdm(enumerate(train_loader), total=len(train_loader))\n    for step, data in bar:\n        images = data['image'].to(device, dtype=torch.float)\n        labels = data['label'].to(device, dtype=torch.long)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        \n        # crossentropy loss\n        loss = criterion(outputs, labels)\n        # Focal Loss\n        #criterion = FocalLoss(gamma=0.7)\n        #m = torch.nn.Softmax(dim=-1)\n        #loss = criterion(m(outputs), labels)\n        \n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * images.size(0)\n    # Update learning rate using the scheduler\n    if scheduler:\n        scheduler.step()\n        \n        # Log the training loss to TensorBoard\n        writer.add_scalar('loss/train_batch', loss.item(), epoch * len(train_loader) + step)\n    \n    train_loss /= len(train_loader.dataset)\n    # Log the average training loss for the epoch to TensorBoard\n    writer.add_scalar('loss/train_epoch', train_loss, epoch)\n    # gc.collect()\n    return train_loss\n\ndef validate_one_epoch(model, valid_loader, criterion, device, writer, epoch):\n    model.eval()\n    valid_loss = 0.0\n    valid_acc = 0.0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        bar_val = tqdm(enumerate(valid_loader), total=len(valid_loader))\n        for step, data in bar_val:\n            images = data['image'].to(device, dtype=torch.float)\n            labels = data['label'].to(device, dtype=torch.long)\n            outputs = model(images)\n            \n            # crossentropy loss\n            loss = criterion(outputs, labels)\n            # Focal Loss\n            #criterion = FocalLoss(gamma=0.7)\n            #m = torch.nn.Softmax(dim=-1)\n            #loss = criterion(m(outputs), labels)\n        \n            valid_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(model.softmax(outputs), 1)\n            acc = torch.sum( predicted == labels )\n            valid_acc  += acc.item()\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n        \n            writer.add_scalar('loss/valid_batch', loss.item(), epoch * len(valid_loader) + step)\n            writer.add_scalar('acc/valid_batch', acc.item(), epoch * len(valid_loader) + step)\n    valid_loss /= len(valid_loader.dataset)\n    valid_acc /= len(valid_loader.dataset)\n    bal_acc = balanced_accuracy_score(all_labels, all_preds)\n    # At the end of your validation loop:\n    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n    micro_f1 = f1_score(all_labels, all_preds, average='micro')\n    weighted_f1 = f1_score(all_labels, all_preds, average='weighted')\n\n    # Logging to TensorBoard\n    writer.add_scalar('loss/val_epoch', valid_loss, epoch)\n    writer.add_scalar('acc/val_epoch', valid_acc, epoch)\n    writer.add_scalar('balanced_acc/val_epoch', bal_acc, epoch)\n    writer.add_scalar('F1/macro', macro_f1, epoch)\n    writer.add_scalar('F1/micro', micro_f1, epoch)\n    writer.add_scalar('F1/weighted', weighted_f1, epoch)\n    # in order to put multiple lines within one graph\n    #writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n    #                        'xcosx':i*np.cos(i/r),\n    #                        'tanx': np.tan(i/r)}, i)\n    return valid_loss, valid_acc, bal_acc, weighted_f1\n\ndef train_model(model, train_loader, valid_loader, optimizer, criterion, device, num_epochs, scheduler, save_model_path=None):\n    model_name = \"model_epochs\" + str(CONFIG[\"num_epochs\"]) + \"_bs\"+str(CONFIG[\"train_batch_size\"] )+ \"_opt\" +CONFIG[\"optimizer\"]+ \"_sched\" + CONFIG[\"scheduler\"] + \"_lr\"+str(CONFIG[\"learning_rate\"])+ \"_wd\" + str(CONFIG[\"weight_decay\"])\n    print(f\"Training model: {model_name}\")\n    datetime_now =  datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n    if not save_model_path:\n        save_model_path = 'best_model_checkpoint' + datetime_now + '.pth'\n    print(f\"Path for saving model: {save_model_path}\")\n    # Initialize TensorBoard writer\n    writer = SummaryWriter('logs/fit/' + model_name)\n    early_stopping = EarlyStopping(patience=CONFIG[\"patience\"], verbose=True, path=save_model_path)\n    #if scheduler_type:\n    #    print(f\"Define {scheduler_type} scheduler\")\n    #    scheduler = get_lr_scheduler(optimizer, scheduler_type, num_epochs=num_epochs)\n    \n    for epoch in range(num_epochs):\n        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, writer, epoch, scheduler)\n        valid_loss, valid_acc, bal_acc, weighted_f1 = validate_one_epoch(model, valid_loader, criterion, device, writer, epoch)\n        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss:.4f}, Validation loss: {valid_loss:.4f}, Validation acc: {valid_acc:.4f}, Balanced acc: {bal_acc:.4f}, Weighted F1-Score: {weighted_f1:.4f}\")\n        # Call early stopping\n        if CONFIG[\"early_stopping\"]:\n            early_stopping(valid_loss, model)\n            if early_stopping.early_stop:\n                print(\"Early stopping\")\n                break\n        writer.close()\n\n        try:\n            mlflow.log_metrics({\n                'epoch': epoch,\n                'train_loss': train_loss,\n                'valid_loss': valid_loss,\n                'valid_acc': valid_acc,\n                'balanced_acc': bal_acc,\n                'weighted_f1': weighted_f1\n            }, step=epoch)\n        except: \n            pass\n            \n    return train_loss, valid_loss, valid_acc, save_model_path\n    # Load the last checkpoint with the best model\n    #model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.770913Z","iopub.execute_input":"2023-11-24T19:57:51.771268Z","iopub.status.idle":"2023-11-24T19:57:51.794825Z","shell.execute_reply.started":"2023-11-24T19:57:51.771238Z","shell.execute_reply":"2023-11-24T19:57:51.794007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_on_holdout(model, CONFIG, df_test, TRAIN_DIR=None, val_size=1.0, n_tiles=1):\n    if not CONFIG[\"is_submission\"]:\n        model.eval()\n        test_dataset = CancerTilesDataset(df_test, TRAIN_DIR, transforms=data_transforms[\"valid\"], mode=\"test\", split=1.0, n_tiles=n_tiles)\n        test_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'], \n                                  num_workers=2, shuffle=False, pin_memory=True)\n        print(f\"Test-Dataset Size: {len(test_dataset)}\")\n\n        preds = []\n        labels_list = []\n        test_acc = 0.0\n\n        with torch.no_grad():\n            bar = tqdm(enumerate(test_loader), total=len(test_loader))\n            for step, data in bar: \n                # print(step)\n                images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)\n                labels = data['label'].to(CONFIG[\"device\"], dtype=torch.long)\n\n                batch_size = images.size(0)\n                outputs = model(images)\n                _, predicted = torch.max(model.softmax(outputs), 1)\n                preds.append(predicted.detach().cpu().numpy() )\n                labels_list.append(labels.detach().cpu().numpy() )\n                acc = torch.sum(predicted == labels )\n                test_acc  += acc.item()\n        test_acc /= len(test_loader.dataset)\n        preds = np.concatenate(preds).flatten()\n        labels_list = np.concatenate(labels_list).flatten()\n        pred_labels = encoder.inverse_transform( preds )\n        \n        # Calculate Balanced Accuracy\n        bal_acc = balanced_accuracy_score(labels_list, preds)\n        # Calculate Confusion Matrix\n        conf_matrix = confusion_matrix(labels_list, preds)\n        macro_f1 = f1_score(labels_list, preds, average='macro')\n\n    \n        print(f\"Test Accuracy: {test_acc}\")\n        print(f\"Balanced Accuracy: {bal_acc}\")\n        print(f\"Confusion Matrix: {conf_matrix}\")\n        \n        # add to validation dataframe\n        num_samples = len(df_test)\n        for i in range(0,n_tiles):\n            df_test[f\"label_tile_{str(i)}\"] = labels_list[i*num_samples:(i+1)*num_samples]\n            df_test[f\"pred_tile_{str(i)}\"] = preds[i*num_samples:(i+1)*num_samples]\n            df_test[f\"pred_label_tile_{str(i)}\"] = pred_labels[i*num_samples:(i+1)*num_samples]\n            #df_test[\"pred\"] = preds\n            #df_test[\"pred_labels\"] = pred_labels\n        try: \n            mlflow.log_metrics({\n                'test_acc': test_acc,\n                'test_balanced_acc': bal_acc,\n                'test_f1_score': macro_f1,\n            })\n        except: \n            pass\n        return df_test\n    else:\n        print(\"Skip validation on training set due to submission!\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.795990Z","iopub.execute_input":"2023-11-24T19:57:51.796247Z","iopub.status.idle":"2023-11-24T19:57:51.810278Z","shell.execute_reply.started":"2023-11-24T19:57:51.796225Z","shell.execute_reply":"2023-11-24T19:57:51.809434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG[\"weighted_loss\"]:\n    class_weights = get_class_weights(df_train).to(CONFIG['device'], dtype=torch.float)\n    print(f\"Class weights: {class_weights}\")\nelse:\n    class_weights=None\ncriterion = nn.CrossEntropyLoss(weight=class_weights)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:57:51.811541Z","iopub.execute_input":"2023-11-24T19:57:51.811903Z","iopub.status.idle":"2023-11-24T19:57:56.766822Z","shell.execute_reply.started":"2023-11-24T19:57:51.811871Z","shell.execute_reply":"2023-11-24T19:57:56.765823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Shape df_train: {df_train.shape}, Shape df_test: {df_test.shape}\")\nwith mlflow.start_run(experiment_id=mlflow_experiment_id) as run:\n    train_loader, valid_loader, df_train_fold = get_dataloaders(df_train.copy(), n_tiles=CONFIG[\"n_tiles\"])\n\n    model = UBCModel(CONFIG['model_name'], CONFIG['num_classes'], pretrained=False , checkpoint_path=CONFIG[\"checkpoint_path\"])\n    # model.load_state_dict(torch.load(CONFIG[\"checkpoint_path\"]))\n    model.to(CONFIG['device']);\n\n    optimizer = get_optimizer(CONFIG[\"optimizer\"], model)\n    scheduler = fetch_scheduler(optimizer)\n\n    _, _, _, save_model_path = train_model(model, train_loader, valid_loader, optimizer, criterion, CONFIG[\"device\"], CONFIG[\"num_epochs\"], scheduler)\n    model.load_state_dict(torch.load(save_model_path))\n\n    \n    print(\"Validate on Holdout Set:\")\n    df_test = test_on_holdout(model, CONFIG, df_test, TRAIN_DIR, val_size=1, n_tiles=CONFIG[\"n_tiles_test\"])\n    df_test_file_path = \"df_test_results.csv\"\n    df_test.to_csv(df_test_file_path, index=False)\n    try: \n        mlflow.log_params(CONFIG)\n        mlflow.pytorch.log_model(model, \"model\")\n        mlflow.log_params(save_model_path)\n        mlflow.log_artifact(df_test_file_path)\n        print_logged_info(mlflow.get_run(run_id=run.info.run_id))\n    except:\n        pass\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T16:54:55.040041Z","iopub.execute_input":"2023-11-22T16:54:55.040427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('/kaggle/working/best_model_checkpoint' + CONFIG[\"datetime_now\"] + '.pth'))\n# df_test = test_on_holdout(model, CONFIG, df_test, TRAIN_DIR, val_size=1)\n# df_test","metadata":{"execution":{"iopub.status.busy":"2023-11-22T16:54:30.959596Z","iopub.status.idle":"2023-11-22T16:54:30.959956Z","shell.execute_reply.started":"2023-11-22T16:54:30.959789Z","shell.execute_reply":"2023-11-22T16:54:30.959806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UBCModel(CONFIG['model_name'], CONFIG['num_classes'], pretrained=False , checkpoint_path=None)\nmodel.load_state_dict(torch.load(\"/kaggle/input/effnet-version-28/best_model_checkpoint2023-11-21_15-47-39.pth\"))\nmodel.to(CONFIG['device']);","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:58:16.905615Z","iopub.execute_input":"2023-11-24T19:58:16.906004Z","iopub.status.idle":"2023-11-24T19:58:18.453133Z","shell.execute_reply.started":"2023-11-24T19:58:16.905973Z","shell.execute_reply":"2023-11-24T19:58:18.452382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = test_on_holdout(model, CONFIG, df_test, TRAIN_DIR, val_size=1, n_tiles=CONFIG[\"n_tiles_test\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T19:58:27.185562Z","iopub.execute_input":"2023-11-24T19:58:27.186304Z","iopub.status.idle":"2023-11-24T19:59:49.544665Z","shell.execute_reply.started":"2023-11-24T19:58:27.186271Z","shell.execute_reply":"2023-11-24T19:59:49.543659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}